{"posts":[{"title":"ThreadLocal 为什么要这么实现？","text":"多线程环境下，编程需要考虑并发安全问题。常规思路是通过锁来实现，ThreadLocal 则提供了另一种线程安全的实现方式：避免共享。通过 ThreadLocal 定义的变量，不同的线程都会拥有这个变量的副本，没有共享，也就没有并发问题了。 具体的使用方式可以看 JDK 源码中提供的示例，下面这个类中，定义了一个静态私有的 ThreadLocal 变量，为每个线程生成唯一标识。当一个线程首次调用 get 方法时，会调用初始化方法 initialValue，为当前线程分配唯一的 thread id，并且在之后同一个线程再次调用 get 方法时，直接返回这个值。 这里区分两个概念，一个是 ThreadLocal 变量，一个是 ThreadLocal 变量“包裹”的对象（在这个例子中是一个 Integer 对象）。准确来说，ThreadLocal 变量是唯一的，不同线程持有的是 ThreadLocal “包裹”的对象的副本。 1234567891011121314151617public class ThreadId { // Atomic integer containing the next thread ID to be assigned private static final AtomicInteger nextId = new AtomicInteger(0); // Thread local variable containing each thread's ID private static final ThreadLocal&lt;Integer&gt; threadId = new ThreadLocal&lt;Integer&gt;() { @Override protected Integer initialValue() { return nextId.getAndIncrement(); } }; // Returns the current thread's unique ID, assigning it if necessary public static int get() { return threadId.get(); }} 实现原理介绍 ThreadLocal 是如何实现的前，可以尝试自己来实现这样的效果。很容易想到，可以在 ThreadLocal 内创建一个 Map，key 是线程，value 是线程持有的变量。示意图如下所示。 ThreadLocal 持有 Map 但实际上 Java 中的实现，这个 Map 是保存在 Thread 对象中的，key 是 ThreadLocal，value 是线程持有的变量，示意图如下所示，核心代码实现也很简单。 Thread 持有ThreadLocal Map 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadLocal&lt;T&gt; { public T get() { Thread t = Thread.currentThread(); // 从当前线程中获取 ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) { // ThreadLocal 作为 key，从 map 中获取 value ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } // map 还没初始化，这里执行初始化逻辑 return setInitialValue(); } public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); }}public class Thread { ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap getMap(Thread t) { return t.threadLocals; }} Java 中的实现和自定义实现，哪种方式更好呢，显然 Java 的实现更好一点，这里我总结了一下几点优势，这也是为什么 Java 要这样实现 ThreadLocal 的原因。 ThreadLocal 仅仅作为工具类，不持有任何线程相关的数据，而是将这些数据保存在 Thread 对象中，设计上更加容易理解 自定义实现中使用需要使用并发安全的 Map 来存放数据，存在锁竞争，而 Java 实现中每个线程对各自数据的读写都是独立的，没有并发问题，性能更好 自定义实现中，ThreadLocal 对象持有线程引用，通常 ThreadLocal 对象的生命周期要更长，如果线程没有主动删除对应的 key-value，会导致 Thread 对象无法被回收，导致内存泄漏 内存泄漏前面我们提到 Java 这样实现 ThreadLocal 是有助于避免内存泄漏的，因为 Thread 对象持有线程本地数据，当线程销毁后，它所持有的对象副本也会被 GC 回收。 但前面我们忽略了一点，因为程序中往往是通过线程池来使用线程的，所以线程的生命周期可能也非常长。所以 Thread 对象中持有线程本地数据时，也可能导致内存泄漏。 所以 Java 实现中还做了一项优化，就是 ThreadLocalMap 中的 Entry 实现为弱引用，通过弱引用指向 key，也就是 ThreadLocal 变量，这样当程序中声明的 ThreadLocal 变量声明周期结束后，因为这里是弱引用，所以可以被顺利回收。 123456789101112static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } }} 那是否 Java 实现的 ThreadLocal 一定不会发生内存泄漏呢？不是的，因为 ThreadLocalMap 中 Entry 的 value 并不是弱引用，如果程序中没有及时将 value 从 map 中移除，即使 value 的生命周期结束了，也无法被回收，这里还是会发生内存泄漏。为了避免发生这种情况，我们需要在代码中手动释放 Entry 对 value 的强引用，使用示例如下： 123456789101112ExecutorService es;ThreadLocal tl;es.execute(()-&gt;{ //ThreadLocal增加变量 tl.set(obj); try { // 省略业务逻辑代码 }finally { //手动清理ThreadLocal tl.remove(); }}); 应用场景了解了 ThreadLocal 的实现原理，不知道你会不会有这样的疑问，在什么情况下才需要用到 ThreadLocal 呢？如果只是为了避免共享，我直接将要用的变量声明为局部变量不可以吗？ 答案是不可以，考虑这样两种场景： 这个对象创建过程非常耗时、耗资源，如果每次使用时都重新创建可能导致性能问题 这个对象只能在某个方法中获取，但需要在很多方法中使用，如果声明为局部变量，则需要在整个链路中所有方法中进行传递，如果这个变量和业务逻辑没有紧密联系，会非常影响代码可读性、可维护性 所以，通常我们会把一些线程间不需要共享，但在同一线程，多个方法调用中都可能使用到，同时和业务逻辑关系不紧密的数据，放在 ThreadLocal 中。 看几个具体的例子： 程序中经常会用 traceId 把一次用户请求在系统中调用的路径串联起来，traceId 信息非常适合通过 ThreadLocal 保存 用户登陆系统后，针对用户的每次请求，可以从 Session 或者Token 中获取用户信息，保存到 ThreadLocal 中，在需要使用的时候可以很方便的获取到 从数据库连接池获取链接后，Connection 对象放到 ThreadLocal 中，Spring 的事务管理，底层实现就利用的这样的机制 使用 ThreadLocal 时，还需要特别注意以下几种情况： 配合线程池使用时，要知道线程池中的线程生命周期会非常长，会在不同的请求间复用，所以一定要主动 remove 使用完毕的 ThreadLocal 变量，防止内存泄漏，也防止对下次请求造成影响 异步调用中，ThreadLocal 是无法传递的，要避免在这样的场景中依赖 ThreadLocal 变量，或者手动实现 ThreadLocal 的跨线程传递 InheritableThreadLocalJava 中还提供了一个 InheritableThreadLocal 类来支持父子线程之间线程本地存储变量的继承，InheritableThreadLocal 是 ThreadLocal 的子类，之所以能实现继承特性，其实是在初始化线程时，有一步操作，专门将父线程的成员变量 inheritableThreadLocals 指向的 ThreadLocalMap 中的变量拷贝到了子线程中。 12345678910public class Thread { private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { ... // 将父线程的 inheritableThreadLocals 指向的 ThreadLocalMap 中的变量拷贝到当前线程 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); ... }} 总结并发编程中，ThreadLocal 通过避免共享的方式实现了线程安全。Java 中 ThreadLocal 的实现，是将线程本地数据通过 ThreadLocalMap 放在的 Thread 对象中，ThreadLocal 变量做 key，ThreadLocal “包裹”的对象副本做 value。并且 ThreadLocalMap 的 Entry 实现为弱引用，指向ThreadLocal 变量，防止内存泄漏。但是要想完全避免内存泄漏，使用时要记得及时释放对 value 的强引用。最后，要记得全链路 traceId，登陆用户信息，Spring 事务中的数据路链接等典型的应用场景 参考 线程本地存储模式：没有共享，就没有伤害 ThreadLocal","link":"/2023/11/07/thread-local/"},{"title":"Redis 做缓存可能面临哪些问题？","text":"Redis 做缓存是提升系统性能的利器，但同时也会面临一些问题。本文总结了使用缓存常见的几种问题，以及应对这些问题的方法。 缓存穿透对数据库做缓存时，大部分流量从缓存中返回，少部分未命中缓存的流量才会请求到数据库中，数据库的压力就会比较低。但如果数据在数据库中不存在，自然也不会在缓存中存在，这类流量每次都无法命中缓存，都会请求到数据库中，这样缓存就无法起到降低数据库压力的作用。这种查询不存在数据的现象叫做缓存穿透。 缓存穿透可能是业务逻辑固有的问题，也可能是恶意攻击导致的。针对这两种情况，可以采取的应对措施也不同。 业务逻辑导致的缓存穿透对返回空的 key 值也进行缓存，注意这里是正常返回但是结果为空的情况，发生异常时不能当作空数据进行缓存。 恶意攻击导致的缓存穿透如果是恶意攻击刻意构造不存在的 key 发起请求，缓存空数据的方案就不可行了，这种情况可以借助布隆过滤器来对请求进行一层过滤。 布隆过滤器是用最小代价来判断元素是否存在于某个集合中的方法。虽然维护布隆过滤器需要一定的成本，但是相比攻击导致的资源损耗还是值得的。 缓存击穿如果缓存中的某些热点数据因为某种原因突然失效，比如典型地由于超期而失效，同时又有大量针对该数据的请求发送进来，那么这些请求因为无法命中缓存，都会到达数据库中，导致数据库压力突增，这种现象叫做缓存击穿。 针对缓存击穿，可以采取两种方案： 加锁同步当缓存数据失效时，请求会查询数据库，然后再将查询到的数据写会回缓存。如果将这部逻辑通过互斥锁保护起来，这样最多只有一个请求能够达到数据库中，其它请求可以采取阻塞或者重试的策略。注意 redis 是分布式缓存，这里通常需要采用分布式锁来进行保护。 热点数据手动管理缓存击穿是由于热点数据失效导致的问题，对于这类数据，我们可以通过代码进行有计划的更新，避免自缓存自动失效。 缓存雪崩大批量不同的数据在短时间内一起失效的话，针对这些数据的请求都会击穿缓存，到达数据库，导致数据库压力剧增，这种现象叫过缓存雪崩。 缓存雪崩可能是由于服务有专门的缓存预热功能，或者大量数据都是由某一次冷操作加载的，这样导致由此载入缓存的数据具有相同的过期时间，在同一时刻一起失效；还可能是缓存服务崩溃重启，造成大量数据同时失效。 针对缓存雪崩，我们可以采取以下三种方案： 提升缓存系统的可用性，比如集群部署，支持故障检测、主备切换等； 使用本地缓存，各个服务节点的本地缓存通常具有不同的加载时间，从而过期时间就会比较分散 将缓存的过期时间从固定时间改为一个时间段内的随机事件，比如原来是两个小时过期，现在设置为 110 分钟到 130 分钟之间的某个随机值 缓存污染缓存污染是指缓存和数据库数据不一致的现象。通常使用缓存时，不会追求强一致性，但是最终一致性还是需要保证的。 缓存污染问题通常是由于代码开发不规范导致的，比如更新缓存数据后，由于某些原因，比如业务发生异常回滚，导致数据没有写入数据库中，这时缓存中数据是新的，但是数据库还是就数据。 为了尽可能保证缓存数据的一致性，业内总结了很多更新缓存的设计模式，包括 Cache Aside、Read/Write Through、Write Behind Caching 等等，其中最常用的是 Cache Aside 模式，因为它最简单、成本最低。主要内容可以概括为以下两点： 读数据时，首先读缓存，没有缓存，再度数据源，然后将数据写入缓存，再响应请求 写数据时，先写数据源，然后失效缓存 写数据时，这里要注意两点。 一个是先后顺序一定是先数据源，再缓存。如果先失效缓存，再更新数据源，一定存在一段时间内缓存已经删除完毕，数据源还未更新。此时如果有读请求进来，无法命中缓存，就会到达数据源中。 此时读到的还是旧数据，随后又会写到缓存中。等数据更新完成后，就出现了缓存中是旧数据，数据源是新数据，两者数据不一致的情况。 二是应当失效缓存，而不是更新缓存。因为如果是更新缓存，更新过程中数据源又被其它请求修改，缓存要面临多次赋值的复杂时序问题。如果是失效缓存，则无论这个过程中数据源更新了多少次，都不会产生影响。 当然，有一种情况下 Cache Aside 模式也会导致数据不一致，就是如果某个数据是从未被缓存过的，或是恰好超期失效，或是恰好因为更新被失效，读请求就会达到数据源中。如果对数据源的又一个写操作正好发生在查询请求之后，结果回填到缓存前，也会出现缓存中数据和数据源不一致的情况。 相对而言，这种缓存不一致出现的条件更为苛刻一点。通过设置合理的过期时间，可以控制这种情况下的最长影响时间。 通常情况下，Cache Aside 模式依然是一种低成本更新缓存，且能够获得相对可靠结果的解决方案。 BigKeystring 类型超过 10KB，hash、list、set、zset 元素个数超过 5000，可以认为是 big key，可能导致 Redis 性能下降。 BigKey 的产生可能有下面这些原因： 未正确使用 Redis，如使用 String 类型的 key 存放大体积二进制文件型数据 业务规划不足，没有对 key 中的成员进行合理的拆分，造成个别 key 中的成员数量过多 未定期清理无效数据，造成如 HASH 类型 key 中的成员持续不断地增加 服务发生异常，如使用 LIST 类型 key 的业务消费侧发生代码故障，造成对应key 的成员只增不减 BigKey 可能导致以下问题： 大量占用内存，引发操作阻塞或重要的 key被逐出，甚至引发内存溢出 集群架构下，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡 命令执行效率下降，如 lrange、hgetall 等时间复杂度为 O(n) 的命令 对 BigKey 执行读请求，会使 Redis 实例的带宽被占满，影响服务性能 对 BigKey 执行删除操作，易造成主库较长时间的阻塞，进而可能引发同步中断或主从切换 BigKey 需要更多的网络带宽来传输可能导致网路阻塞，特别是在进行备份、复制或者集群间数据同步时 如何定位 BigKey： 通过 redis-cli 的 bigkeys 参数查找 BigKey 通过 Redis 内置命令 DEBUG OBJECT、MEMORY USAGESTRLEN、LLEN 等对目标 Key 进行分析 使用第三方工具redis-rdb-tools，使用过程中会先使用 bgsave 命令dump一个rdb 镜像，然后对这个镜像进行分析 我们可以参考以下几种方案来解决 BigKey 的问题。 第一，尝试压缩 value。 第二，将 BigKey 拆分成多个小 key。 第三，对 BigKey 进行清理，迁移到其它更适合的存储中。 第四，对集合中的过期数据进行定期清理。 第五，删除 BigKey 时，使用 redis4.0 新特性，非阻塞删除。 HotKeyHotKey 是指 Redis 中访问频率特别高的 key。在秒杀、爆款商品、爆款新闻等场景中经常会出现 HotKey，可能导致以下问题： 占用 Redis server 端大量的 CPU 资源，导致整体性能下降 如果是集群架构，会产生访问倾斜，某个内存分片被大量访问，可能导致该分片出现连接数耗尽、性能下降等问题 增加网络流量，可能导致网路阻塞 出现缓存击穿现象，导致数据库压力突增，影响其它业务 访问量超出 Redis server 上限，导致服务崩溃，进一步导致缓存雪崩 如何定位 HotKey： 通过 redis-cli 的 hotkeys 参数查找 HotKey 在业务层增加相应的代码对 Redis 的访问进行监控分析 通过 MONITOR 命令找出 HotKey 我们可以参考以下几种方案来解决 HotKey 的问题。 第一，可以增加本地缓存，来降低 HotKey 的访问频率。不过这种方案会面临缓存不一致、消耗本地内存的问题。 第二，对 HotKey 进行复制，比如将 HotKey foo 复制出 3 个内容完全一样的 Key 并名为 foo2、foo3、foo4。该方案的缺点在于需要联动修改代码，同时也有数据一致性的问题。 第三，在客户端和 Redis server 间接入 proxy 层，通过 proxy 实现读写分离以及读流量在多个从节点间的负载均衡。在请求量极大的场景下，读写分离架构会产生不可避免的延迟，此时会有读取到脏数据的问题。 第四，同样是接入 proxy 层，但 proxy 在这里承担缓存 HotKey 查询结果的职责。类似方案一，改进的地方是对业务层是透明的。 总结本文总结了 Redis 作为缓存的常见问题及解决方案，不同的业务场景下可能会面临不同的问题，可以采取的方案也不尽相同。可以遵循一个原则进行选择，“能满足需求的前提下，最简单的系统就是最好的系统”。 参考 分布式缓存如何与本地缓存配合，提高系统性能？ 发现并处理Redis的大Key和热Key Understanding and Solving HotKey and BigKey issues in Redis Redis Hotspot Key Discovery and Common Solutions","link":"/2023/11/13/redis-problem/"},{"title":"保证缓存最终一致性的方案有哪些？","text":"随着业务数据的增多和业务流量的增长，如果只依赖数据库来承接所有的流量，服务的性能和稳定性都会面临风险。由于互联网业务往往是读多写少的场景，所以非常适合增加缓存来提升系统的响应能力，同时降低数据库的访问压力。 使用缓存在带来好处的同时，也带来了数据一致性的问题。针对这个问题，业界已经总结了几种常用的更新缓存的设计模式，来保证缓存和数据库的最终一致性。注意这里是最终一致性，因为使用的缓存的大部分场景，最终一致性足以满足业务需求，很少有需要强一致性的场景。 接下来我们会分别介绍这几种更新缓存的设计模式。 Cache-AsideCache-Aside 叫做旁路缓存模式。下图描述了这种模式的处理流程。处理读请求时，首先查询缓存，如果缓存数据有效，则直接返回，否则查询数据库，然后将数据更新到缓存中，再返回数据；处理写请求时，首先更新数据库，然后删除缓存。 Cahce-Aside 模式读写请求处理流程 读请求的过程很容易理解，关于写请求，可能会有这么几个疑问。 问题1：为什么是先操作数据库，再操作缓？先后顺序一定是先数据源，再缓存，这是非常重要的一点。因为如果先删除缓存，再更新数据源，则会存在一段时间内缓存已经删除完毕，数据源还未更新。此时如果有读请求进来，无法命中缓存，就会到达数据源中。 此时读到的还是旧数据，随后又会写到缓存中。等数据更新完成后，就出现了缓存中是旧数据，数据源是新数据，两者数据不一致的情况。下图描述了这种场景。 关于延时双删 为了解决先删除缓存，再更新数据库这种方案导致的问题，网上的资料经常看到一种叫做“延时双删”的方案。即在更新数据库后，延迟一段时间再次删除缓存。显然，再次删除缓存的操作应该在读请求更新缓存后，所以延迟的时间一般要比读请求的耗时稍大一些，通常可以采用 sleep 或者延迟队列实现。 我个人认为这种方案不具有应用价值。一方面是延时的时间很难界定；另一个更重要的原因是再更新数据库之前删除缓存并没有带来任何好处，反而要为此采用再次删除的操作作为补偿机制，那我们直接不要在更新数据前删除缓存就好了。 延时双删 问题2：为什么是删除缓存，是否能直接更新缓存呢？1）因为如果是更新缓存，更新过程中数据源又被其它请求修改，缓存要面临多次赋值的复杂时序问题，可能会导致数据不一致。下图描述了这种场景。而删除操作是幂等的，不会出现这种情况。 2）如果缓存是经过大量的计算得到的，在写数据时去更新缓存可能是一笔不小的开销，如果更新缓存后没有来的及使用，缓存就再次被更新（这被称为缓存扰动），则会造成资源的浪费；读数据时更新缓存则符合懒加载的思想。 问题3：Cache-Aside 模式一定能保证数据一致性吗？不一定，有可能出现数据不一致的情况。 1）当读请求查询缓存时，如果数据从未被缓存过或者缓存正好因超期而失效，当从数据库查询数据后，更新到缓存前，如果有写请求在此期间执行完成，则会导致缓存中的数据被旧数据覆盖。执行过程如下图所示： 这种情况发生要满足下面两个条件： 数据从未被缓存过或者刚好失效 读写并发执行，读请求查询数据库的执行要早于写请求更新数据库开始，但读请求执行完成要晚于写请求 所以这种不一致的场景产生的条件还是比较严格的，在实际生产环境中出现的可能很小。 2）另外，如果写请求删除缓存失败，也会导致缓存中数据落后于数据库中的数据。针对这种情况，通常可以采取以下几种机制。 缓存设置过期时间 通常缓存都会设置一个过期时间，如果出现不一致，最多持续时长为缓存的过期时间。如果业务上可以接受，这是代价最小的解决方案； 删除重试机制 正如前面提到的，删除操作是幂等的，所以很方便可以进行重试，但如何重试是值得考虑的一个问题； 首先同步重试会影响请求的性能，异步重试可以通过消息队列来实现，比如删除失败后写一条消息到消息队列中，或者更新数据库后直接写一条消息到队列中，通过消息队列执行删除操作，并自动进行重试。 这种方案的问题是为原本很简单的操作引入了太大的复杂性，非必要不建议采取，而且对缓存系统进行重试也要慎重对待，当系统出现问题时，重试导致的流量激增往往会导致问题进一步恶化。 利用事务 还有一种方案是将更新数据库的操作和删除缓存的操作放到同一个事务中，删除失败时回滚事务。 这种方案实现起来很简单，但不建议使用，原因如下： 在事务操作中增加一次网络调用，会延长事务的持续时间，相当于降低了数据库的并发性能 缓存系统的问题会引起连锁反应，导致数据库大量操作回滚，本来只是数据一致性的问题，现在则会影响到整个系统的可用性 Read-ThroughRead-Through 叫做读穿透模式，和 Cache-Aside 的读请求流程基本一样，不同的是多了一个访问控制层。问控制层封装了缓存和数据库交互的逻辑，业务层只和访问控制层进行交互，实现更加简洁，良好的封装性也让程序更容易维护和移植。 在我看来，这种方案相比 Cache-Aside 只是更加强调了代码实现上的封装和解耦，核心思路是完全一样的。 Write-ThroughWrite-Through 叫做直写模式，它也提供了访问控制层，和 Cache-Aside 的区别是，Write-Through 更新数据库后会直接更新缓存，而不是删除缓存。 当然这里如果是先更新缓存，再更新数据库也是可以的。但无论如何，更新缓存而不是删除缓存，就会面临前面提到的两个问题： 并发更新时缓存要面临多次赋值的复杂时序问题 对写请求的性能影响及缓存扰动问题 第一个问题是必须要解决的，典型的方案是通过分布式锁来保证两个操作的原子性，当然不可避免地会影响系统的并发处理能力。 一个简化的方式是将两个操作都放到数据库的事务中执行，这种方案的问题前面也分析过两点，这里还要再提一点，因为 Redis 并不支持事务，所以极端情况下可能出现 Redis 更新成功，但 MySQL 事务回滚的情况（执行 commit 命令时发生异常）。 关于第二个问题，虽然对写请求的性能有影响，但因为直接更新缓存，读取时就可以快速地从缓存中获取数据。所以 Write-Through 更加适合对读取操作要求较高性能要求的场景。 另外，在 Write-Through 模式下，不管是先更新缓存还是先更新数据库，都存在更新缓存或者更新数据库失败的情况，前面提到的重试机制这里也是奏效的。 Write-BehindWrite-Behind 叫做异步回写模式。和 Read-Through/Write-Through 具有类似的访问控制层，不同的是 Write-Behind 处理写请求时只更新缓存而不更新数据库。对数据库的更新，通过异步批量更新的方式进行，批量写入的时间点可以在数据库负载较低的时间进行。 Write-Behind 模式减轻了数据库压力，写请求延迟低，可以支持更高的吞吐量。但是数据一致性较弱，缓存数据未写入数据库时，直接从数据库中查到的是旧数据。同时对缓存系统的压力比较大，缓存宕机回导致数据丢失，所以要做好缓存系统的高可用。所以，Write-Behind 更加适合大量写操作的场景，比如电商秒杀场景中的减库存。 Write-Around对于非核心业务场景，可以选择在 Cache-Aside 模式下增加缓存过期时间，在写请求中仅仅更新数据库，不做任何删除或者更新缓存的操作，缓存仅能通过过期时间失效。 这种方案实现简单，但数据一致性较差，可能导致用户体验较差，要慎重选择。 基于数据库日志（ MySQL binlog ）增量订阅和消费除了上面介绍的几种缓存更新模式，还有一种方案，就是订阅 MySQL binlog，将数据库更新事件写入 MQ 中，然后在消费逻辑中删除相应的的缓存。 这种方案的优点是删除缓存的逻辑和业务进行了解耦，并且消息队列天然具备重试能力。不过要注意如果 binlog 消费存在较大延迟，在此期间从缓存读取到是旧数据。 因为消费 binlog 不存在并发更新的复杂时序问题，所以这里直接更新缓存也是可以的。但是当读请求正好触发更新缓存时，和 binlog 触发的更新缓存之间也会出现并发更新的时序问题，虽然这种场景出现的概率很小，但还是更加推荐删除缓存而不是更新。 总结以上是业界常用的几种解决缓存一致性的方案，其中，Cache-Aside 模式是以低成本更新缓存，并且获得相对可靠结果的解决方案，适用于大部分场景；另外对于大量写操作的场景，考虑使用 Write-Behind 模式；如果业务中有成熟的 binlog 增量订阅和消费机制，则可以考虑基于 binlog 来维护缓存的一致性。 参考 浅谈缓存最终一致性的解决方案 分布式缓存如何与本地缓存配合，提高系统性能？","link":"/2023/12/19/cache-consistency/"},{"title":"TCP 是如何保证可靠性的？","text":"最近看了网络","link":"/2023/12/19/tcp-reliability/"},{"title":"socket 通信中可能发生哪些异常","text":"socket 是网络编程的基础，业务开发中常用的 HttpClinet、RPC 框架等底层网络通信基础都离不开 socket，在使用这些框架的时候，可能会遇到 connect refused、connect reset by peer 等异常情况，这些异常的含义很容易理解。 但是当发生这些异常的时候，socket 的一些行为细节，更近一步的，TCP 协议中的发生了什么，可能就不是那么直观清晰了。 所以我专门针对 socket 编程中可能出现的异常进行了调研，针对不同的异常情况，给出了 C 语言 socket 编程代码示例，并分析了发生对应情况时 TCP 协议层的具体动作。 拒绝连接异常拒绝连接异常就是服务端拒绝了客户端的连接，在如下这个代码示例中，当我们试图连接到一个本地未监听的端口时，就会收到这样的一个异常信息。 根据 ip 地址和 端口，建立 TCP 连接： 1234567891011121314151617181920212223242526int tcp_client(const char *address, int port) { int socket_fd; socket_fd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_port = htons(port); inet_pton(AF_INET, address, &amp;server_addr.sin_addr); socklen_t server_len = sizeof(server_addr); // 调用 connect 函数建立连接 int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len); if (connect_rt &lt; 0) { // 如果连接发生异常，打印错误日志 error(1, errno, &quot;connect failed &quot;); } return socket_fd;}int main(int argc, char** argv) { char *ip = argv[1]; int port = atoi(argv[2]); int socket_fd = tcp_client(ip, port);} 不启动服务端的情况下，尝试建立连接，终端输出信息如下： 1connect failed : Connection refused (61) 可以看到当发生 Connection refused 异常时，socket 层是由 connect 函数返回了对应的错误码，那么 TCP 协议层发生了什么呢？ 我们知道 TCP 建立连接时需要进行 3 次握手，客户端首先发送 sync 报文段，如果报文段到达了目标主机，但是发现目标端口上没有正在监听的服务，则会发出 RST 报文段作为回复，拒绝此次连接。客户端收到 RST 回答后，通过 connect 函数报告这一错误。 产生 RST 的情况由如下 3 种： sync 报文段到达，但目标端口没有正在监听的服务（如上所述） TCP 想取消一个已有连接 TCP 接收到一个根本不存在的连接上的报文段 连接超时异常还是上一小节的代码示例，如果在建立连接时，指定了一个无法连接的 ip 地址，比如和本机不在同一个局域网的私有 ip 地址，终端会输出如下错误信息： 1connect failed : Operation timed out (60) connect 函数默认情况下是阻塞调用，直到连接建立成功或者报告错误。如果客户端发出的 SYN 包没有任何响应，最终会返回 TIMEOUT 错误。 Linux 下默认的超时时间是 75s，实际应用中这个超时时间是不能接受的，所以在实际的网络通信中我们通常会IO多路复用的方式来建立连接，在调用 select 或者 poll 或者 epoll 函数时指定超时时间。 发生这种情况代表目标主机不可达，可能是 ip 地址写错，或者是网络出现故障。但有时我们会收到明确的 destination unreachable 错误，表示客户端和服务器端路由不通，这是因为客户端收到了路由器或者防火墙报告的 icmp 差错报文。 目标不可达 ICMP 类型 3 表示“Destination Unreachable”（目标不可达），而类型 3 中的不同代码用于指示导致目标不可达的具体原因，常见的代码有如下几种： Code 0: Net Unreachable（网络不可达） Code 1: Host Unreachable（主机不可达） Code 2: Protocol Unreachable（协议不可达） Code 3: Port Unreachable（端口不可达） 所以，当端口不可达时，客户端除了收到 RST 回答，还可能收到 ICMP 差错报文，这可能会因不同的网络设备、操作系统或防火墙设置而有所不同。 连接断开异常上述两个异常是建立连接时可能遇到的，那么当连接建立成功后，因为某种原因连接断开了，会发生什么呢？ socket 中通常只有两种方式来感知 TCP 链路的异常中断，一种是以 read 为核心的读操作，一种是以 write 为核心的写操作。下面我们看下不同场景下通过读写操作来感知 TCP 连接的异常。 对端有 FIN 包发出read 直接感知 FIN 包在正常的连接断开过程中，对端会发送 FIN 报文段，客户端通过 read 接口感知到后，会做出相应的处理，比如关闭连接，释放连接资源。 服务端程序如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859int tcp_server(int port) { int listenfd; listenfd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); server_addr.sin_port = htons(port); int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on)); int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr)); if (rt1 &lt; 0) { error(1, errno, &quot;bind failed &quot;); } int rt2 = listen(listenfd, LISTENQ); if (rt2 &lt; 0) { error(1, errno, &quot;listen failed &quot;); } int connfd; struct sockaddr_in client_addr; socklen_t client_len = sizeof(client_addr); if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) { error(1, errno, &quot;bind failed &quot;); } return connfd;}int main(int argc, char **argv) { int connfd; char buf[1024]; connfd = tcp_server(SERV_PORT); for (;;) { int n = read(connfd, buf, 1024); if (n &lt; 0) { error(1, errno, &quot;error read&quot;); } else if (n == 0) { error(1, 0, &quot;client closed \\n&quot;); } sleep(5); ssize_t write_nc = write(connfd, buf, n); printf(&quot;send bytes: %zd \\n&quot;, write_nc); if (write_nc &lt; 0) { error(1, errno, &quot;error write&quot;); } } exit(0);} 客户端程序如下： 1234567891011121314151617int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int rc; while (1) { rc = read(socket_fd, buf, sizeof(buf)); if (rc &lt; 0) error(1, errno, &quot;read failed&quot;); else if (rc == 0) error(1, 0, &quot;peer connection closed\\n&quot;); else fputs(buf, stdout); } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，客户端终端输出如下： 1peer connection closed 因为阻塞的 read 操作读取到了 FIN 包后返回值为 0，客户端程序感知到 FIN 包后，执行正常退出逻辑。 通过 write 产生 RST，read 调用感知 RST客户端程序如下： 123456789101112131415161718192021222324int main(int argc, char **argv) { int connfd; char buf[1024]; connfd = tcp_server(SERV_PORT); for (;;) { int n = read(connfd, buf, 1024); if (n &lt; 0) { error(1, errno, &quot;error read&quot;); } else if (n == 0) { error(1, 0, &quot;client closed \\n&quot;); } sleep(5); ssize_t write_nc = write(connfd, buf, n); printf(&quot;send bytes: %zd \\n&quot;, write_nc); if (write_nc &lt; 0) { error(1, errno, &quot;error write&quot;); } } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，然后在客户端终端输入“Hello World”，回车后会看到如下错误信息： 1read failed: Connection reset by peer (54) 客户端程序启动后，会阻塞在从标准输入读取数据的 fgets 方法上，因为无法感知到连接已经断开。 当从标准输入获取数据后，会将数据通过 socket 发送给服务端，因为服务端进程已经不存在，所以会返回一个 RST 包，接下来客户端的 read 调用感知到 RST，会返回异常信息，表明连接已断开。 注意 以上实验结果是在 MacOS 14.2.1 上进行的，在 Linux 系统上，这里的 read 调用可能读取到服务端程序关闭时发出的 FIN 包，从而正常关闭，而不是返回 RST 错误。说明不同系统内核中的的 TCP 协议实现可能略有不同。 向一个以关闭连接连续写，导致 SIGPIPE客户端程序如下： 123456789101112131415161718192021static void sig_pipe(int signo) { printf(&quot;SIGPIPE(%d)\\n&quot;, signo);}int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int len; int rc; signal(SIGPIPE, sig_pipe); while (fgets(buf, sizeof(buf), stdin) != NULL) { len = strlen(buf); rc = write(socket_fd, buf, len); if (rc &lt; 0) error(1, errno, &quot;write failed&quot;); } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，然后在客户端终端连续输入数据，第二次回车后会看到如下错误信息： 12SIGPIPE(13)write failed: Broken pipe (32) 和前一个例子类似，当向一个已经关闭的连接发送数据时，会得到 RST 回复。如果客户端再次向这个连接发送数据，则会收到一个 SIGPIPE 信号。如果不捕捉这个信号，应用程序会在毫无征兆的情况下直接退出。 因为我们在程序中捕获了 SIGPIPE 信号，所以可以看到两行输出，第一行是对 SIGPIPE 信号的处理逻辑打印的通知信息，第二行是 write 调用的返回的错误信息。 注意： 在某些 Linux 版本中，第二次 write 操作不会收到 SIGPIPE 信号，而是返回 RST 错误信息。 对端无 FIN 包网络中断导致对端没有 FIN 包当网络中断时，如果网络中其他设备，比如路由器发出了 ICMP 差错报文，说明网络或者主机不可达，这是 read 或者 write 调用会返回 unreachable 错误。 如果没有 ICMP 报文，TCP 并不能及时感知到异常信息。如果此时程序阻塞在 read 方法上，则将无法回复运行，所以通常我们通过设置超时时间来避免这个问题，具体方式下一节分析读取超时异常时会介绍。 如果此时程序首先调用 write 发送了数据，然后阻塞在 read 调用上，系统的 TCP 协议栈会不断尝试将发送缓冲区的数据发送出去，大概在重传 12 次、合计时间约为 9 分钟之后，协议栈会标识该连接异常，这时，阻塞的 read 调用会返回一条 TIMEOUT 错误信息。如果程序继续 wirite 数据，则会收到一个 SIGPIPE 信号。 系统崩溃导致对端没有 FIN 包这种情况和网络中断的情况是类似的，在没有 ICMP 报文的情况下，只能通过 read 或者 write 感知异常。 不同的地方在于，如果系统崩溃之后重新启动，重传的数据到达重启后的系统后，因为系统中没有该连接信息，会返回一个 RST 包。 如果客户端阻塞在 read 调用上，会立即返回 connect reset 错误；如果是 write 调用，也会立即失败，并收到一个 SIGPIPE 信号。 读取超时异常前面提到过，服务端可能因为各种原因断开连接后，没有发出 FIN 包。如果是阻塞套接字，会一直阻塞在 read 调用上，没有办法感知套接字的异常。 所以我们通常会给套接字的 read 操作设置超时。可以说，读取超时异常是上层应用最常见的网络异常之一。 客户端代码如下： 1234567891011121314151617181920212223242526272829int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int len; int rc; // socket read 超时设置为 1s struct timeval tv; tv.tv_sec = 1; tv.tv_usec = 0; setsockopt(socket_fd, SOL_SOCKET, SO_RCVTIMEO, (const char *) &amp;tv, sizeof tv); while (fgets(buf, sizeof(buf), stdin) != NULL) { len = strlen(buf); rc = write(socket_fd, buf, len); if (rc &lt; 0) error(1, errno, &quot;write failed&quot;); sleep(3); rc = read(socket_fd, buf, sizeof(buf)); if (rc &lt; 0) error(1, errno, &quot;read failed&quot;); else if (rc == 0) error(1, 0, &quot;peer connection closed\\n&quot;); else fputs(buf, stdout); } exit(0);} 分别启动服务端和客户端后，在客户端终端输入数据，1s 后会看到如下错误信息： 1read failed: Resource temporarily unavailable (35) 因为客户端程序中，socket 超时时间设置为 1s，而服务端发送数据前 sleep 了 5s，所以这里 read 函数返回读取超时错误信息。 总结本文中总结了 socket 编程可能遇到的几种常见异常场景，并结合 TCP 协议进行了分析，其中，当服务端连接意外中断时，客户端对连接异常信息的检测，可能因不同的条件而产生 Connection Reset、Broken Pipe 等不同的错误信息。读完本篇文章后，如果应用层遇到了类似的问题，我想可以有更加清晰的理解和排查思路。 另外，文章中设计的代码已经上传到了 githug，地址如下：https://github.com/qinjianmin/socket-exception 参考网络编程实战","link":"/2024/01/07/socket-exception/"},{"title":"书单","text":"","link":"/2023/12/25/book-list/"},{"title":"深入理解 Java 中的类加载机制","text":"","link":"/2024/01/08/class-loader-md/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","link":"/tags/ThreadLocal/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"缓存一致性","slug":"缓存一致性","link":"/tags/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"缓存雪崩","slug":"缓存雪崩","link":"/tags/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"},{"name":"缓存穿透","slug":"缓存穿透","link":"/tags/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"},{"name":"BigKey","slug":"BigKey","link":"/tags/BigKey/"},{"name":"HotKey","slug":"HotKey","link":"/tags/HotKey/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"socket","slug":"socket","link":"/tags/socket/"},{"name":"技术成长","slug":"技术成长","link":"/tags/%E6%8A%80%E6%9C%AF%E6%88%90%E9%95%BF/"},{"name":"类加载","slug":"类加载","link":"/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"并发","slug":"java/并发","link":"/categories/java/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"数据库/Redis","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"并发","slug":"Java/并发","link":"/categories/Java/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"网络协议","slug":"网络协议","link":"/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"攻略","slug":"攻略","link":"/categories/%E6%94%BB%E7%95%A5/"},{"name":"JVM","slug":"Java/JVM","link":"/categories/Java/JVM/"}],"pages":[]}