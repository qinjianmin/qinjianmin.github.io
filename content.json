{"posts":[{"title":"ThreadLocal 为什么要这么实现？","text":"多线程环境下，编程需要考虑并发安全问题。常规思路是通过锁来实现，ThreadLocal 则提供了另一种线程安全的实现方式：避免共享。通过 ThreadLocal 定义的变量，不同的线程都会拥有这个变量的副本，没有共享，也就没有并发问题了。 具体的使用方式可以看 JDK 源码中提供的示例，下面这个类中，定义了一个静态私有的 ThreadLocal 变量，为每个线程生成唯一标识。当一个线程首次调用 get 方法时，会调用初始化方法 initialValue，为当前线程分配唯一的 thread id，并且在之后同一个线程再次调用 get 方法时，直接返回这个值。 这里区分两个概念，一个是 ThreadLocal 变量，一个是 ThreadLocal 变量“包裹”的对象（在这个例子中是一个 Integer 对象）。准确来说，ThreadLocal 变量是唯一的，不同线程持有的是 ThreadLocal “包裹”的对象的副本。 1234567891011121314151617public class ThreadId { // Atomic integer containing the next thread ID to be assigned private static final AtomicInteger nextId = new AtomicInteger(0); // Thread local variable containing each thread's ID private static final ThreadLocal&lt;Integer&gt; threadId = new ThreadLocal&lt;Integer&gt;() { @Override protected Integer initialValue() { return nextId.getAndIncrement(); } }; // Returns the current thread's unique ID, assigning it if necessary public static int get() { return threadId.get(); }} 实现原理介绍 ThreadLocal 是如何实现的前，可以尝试自己来实现这样的效果。很容易想到，可以在 ThreadLocal 内创建一个 Map，key 是线程，value 是线程持有的变量。示意图如下所示。 ThreadLocal 持有 Map 但实际上 Java 中的实现，这个 Map 是保存在 Thread 对象中的，key 是 ThreadLocal，value 是线程持有的变量，示意图如下所示，核心代码实现也很简单。 Thread 持有ThreadLocal Map 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class ThreadLocal&lt;T&gt; { public T get() { Thread t = Thread.currentThread(); // 从当前线程中获取 ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) { // ThreadLocal 作为 key，从 map 中获取 value ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } // map 还没初始化，这里执行初始化逻辑 return setInitialValue(); } public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } private T setInitialValue() { T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); }}public class Thread { ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap getMap(Thread t) { return t.threadLocals; }} Java 中的实现和自定义实现，哪种方式更好呢，显然 Java 的实现更好一点，这里我总结了一下几点优势，这也是为什么 Java 要这样实现 ThreadLocal 的原因。 ThreadLocal 仅仅作为工具类，不持有任何线程相关的数据，而是将这些数据保存在 Thread 对象中，设计上更加容易理解 自定义实现中使用需要使用并发安全的 Map 来存放数据，存在锁竞争，而 Java 实现中每个线程对各自数据的读写都是独立的，没有并发问题，性能更好 自定义实现中，ThreadLocal 对象持有线程引用，通常 ThreadLocal 对象的生命周期要更长，如果线程没有主动删除对应的 key-value，会导致 Thread 对象无法被回收，导致内存泄漏 内存泄漏前面我们提到 Java 这样实现 ThreadLocal 是有助于避免内存泄漏的，因为 Thread 对象持有线程本地数据，当线程销毁后，它所持有的对象副本也会被 GC 回收。 但前面我们忽略了一点，因为程序中往往是通过线程池来使用线程的，所以线程的生命周期可能也非常长。所以 Thread 对象中持有线程本地数据时，也可能导致内存泄漏。 所以 Java 实现中还做了一项优化，就是 ThreadLocalMap 中的 Entry 实现为弱引用，通过弱引用指向 key，也就是 ThreadLocal 变量，这样当程序中声明的 ThreadLocal 变量声明周期结束后，因为这里是弱引用，所以可以被顺利回收。 123456789101112static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } }} 那是否 Java 实现的 ThreadLocal 一定不会发生内存泄漏呢？不是的，因为 ThreadLocalMap 中 Entry 的 value 并不是弱引用，如果程序中没有及时将 value 从 map 中移除，即使 value 的生命周期结束了，也无法被回收，这里还是会发生内存泄漏。为了避免发生这种情况，我们需要在代码中手动释放 Entry 对 value 的强引用，使用示例如下： 123456789101112ExecutorService es;ThreadLocal tl;es.execute(()-&gt;{ //ThreadLocal增加变量 tl.set(obj); try { // 省略业务逻辑代码 }finally { //手动清理ThreadLocal tl.remove(); }}); 应用场景了解了 ThreadLocal 的实现原理，不知道你会不会有这样的疑问，在什么情况下才需要用到 ThreadLocal 呢？如果只是为了避免共享，我们直接将要用的变量声明为局部变量不可以吗？ 答案是不可以，考虑这样两种场景： 这个对象创建过程非常耗时、耗资源，如果每次使用时都重新创建可能导致性能问题 这个对象只能在某个方法中获取，但需要在很多方法中使用，如果声明为局部变量，则需要在整个链路中所有方法中进行传递，如果这个变量和业务逻辑没有紧密联系，会非常影响代码可读性、可维护性 所以，对于一些线程间不需要共享，但在同一线程，多个方法调用中都可能使用到的数据，如果这些数据获创建程很耗资源或者和业务逻辑关系不紧密，那我们就可以把它们放在 ThreadLocal 中。 看几个具体的例子： 程序中经常会用 traceId 把一次用户请求在系统中调用的路径串联起来，traceId 信息非常适合通过 ThreadLocal 保存 用户登陆系统后，针对用户的每次请求，可以从 Session 或者Token 中获取用户信息，保存到 ThreadLocal 中，在需要使用的时候可以很方便的获取到 从数据库连接池获取链接后，Connection 对象放到 ThreadLocal 中，Spring 的事务管理，底层实现就利用的这样的机制 使用 ThreadLocal 时，还需要特别注意以下几种情况： 配合线程池使用时，要知道线程池中的线程生命周期会非常长，会在不同的请求间复用，所以一定要主动 remove 使用完毕的 ThreadLocal 变量，防止内存泄漏，也防止对下次请求造成影响 异步调用中，ThreadLocal 是无法传递的，要避免在这样的场景中依赖 ThreadLocal 变量，或者手动实现 ThreadLocal 的跨线程传递 InheritableThreadLocalJava 中还提供了一个 InheritableThreadLocal 类来支持父子线程之间线程本地存储变量的继承，InheritableThreadLocal 是 ThreadLocal 的子类，之所以能实现继承特性，其实是在初始化线程时，有一步操作，专门将父线程的成员变量 inheritableThreadLocals 指向的 ThreadLocalMap 中的变量拷贝到了子线程中。 12345678910public class Thread { private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { ... // 将父线程的 inheritableThreadLocals 指向的 ThreadLocalMap 中的变量拷贝到当前线程 if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); ... }} 总结并发编程中，ThreadLocal 通过避免共享的方式实现了线程安全。Java 中 ThreadLocal 的实现，是将线程本地数据通过 ThreadLocalMap 放在的 Thread 对象中，ThreadLocal 变量做 key，ThreadLocal “包裹”的对象副本做 value。并且 ThreadLocalMap 的 Entry 实现为弱引用，指向ThreadLocal 变量，防止内存泄漏。但是要想完全避免内存泄漏，使用时要记得及时释放对 value 的强引用。最后，要记得全链路 traceId，登陆用户信息，Spring 事务中的数据路链接等典型的应用场景 参考 线程本地存储模式：没有共享，就没有伤害 ThreadLocal","link":"/2023/11/07/thread-local/"},{"title":"Redis 做缓存可能面临哪些问题？","text":"Redis 做缓存是提升系统性能的利器，但同时也会面临一些问题。本文总结了使用缓存常见的几种问题，以及应对这些问题的方法。 缓存穿透对数据库做缓存时，大部分流量从缓存中返回，少部分未命中缓存的流量才会请求到数据库中，数据库的压力就会比较低。但如果数据在数据库中不存在，自然也不会在缓存中存在，这类流量每次都无法命中缓存，都会请求到数据库中，这样缓存就无法起到降低数据库压力的作用。这种查询不存在数据的现象叫做缓存穿透。 缓存穿透可能是业务逻辑固有的问题，也可能是恶意攻击导致的。针对这两种情况，可以采取的应对措施也不同。 业务逻辑导致的缓存穿透对返回空的 key 值也进行缓存，注意这里是正常返回但是结果为空的情况，发生异常时不能当作空数据进行缓存。 恶意攻击导致的缓存穿透如果是恶意攻击刻意构造不存在的 key 发起请求，缓存空数据的方案就不可行了，这种情况可以借助布隆过滤器来对请求进行一层过滤。 布隆过滤器是用最小代价来判断元素是否存在于某个集合中的方法。虽然维护布隆过滤器需要一定的成本，但是相比攻击导致的资源损耗还是值得的。 缓存击穿如果缓存中的某些热点数据因为某种原因突然失效，比如典型地由于超期而失效，同时又有大量针对该数据的请求发送进来，那么这些请求因为无法命中缓存，都会到达数据库中，导致数据库压力突增，这种现象叫做缓存击穿。 针对缓存击穿，可以采取两种方案： 加锁同步当缓存数据失效时，请求会查询数据库，然后再将查询到的数据写会回缓存。如果将这部逻辑通过互斥锁保护起来，这样最多只有一个请求能够达到数据库中，其它请求可以采取阻塞或者重试的策略。注意 redis 是分布式缓存，这里通常需要采用分布式锁来进行保护。 热点数据手动管理缓存击穿是由于热点数据失效导致的问题，对于这类数据，我们可以通过代码进行有计划的更新，避免自缓存自动失效。 缓存雪崩大批量不同的数据在短时间内一起失效的话，针对这些数据的请求都会击穿缓存，到达数据库，导致数据库压力剧增，这种现象叫过缓存雪崩。 缓存雪崩可能是由于服务有专门的缓存预热功能，或者大量数据都是由某一次冷操作加载的，这样导致由此载入缓存的数据具有相同的过期时间，在同一时刻一起失效；还可能是缓存服务崩溃重启，造成大量数据同时失效。 针对缓存雪崩，我们可以采取以下三种方案： 提升缓存系统的可用性，比如集群部署，支持故障检测、主备切换等； 使用本地缓存，各个服务节点的本地缓存通常具有不同的加载时间，从而过期时间就会比较分散 将缓存的过期时间从固定时间改为一个时间段内的随机事件，比如原来是两个小时过期，现在设置为 110 分钟到 130 分钟之间的某个随机值 缓存污染缓存污染是指缓存和数据库数据不一致的现象。通常使用缓存时，不会追求强一致性，但是最终一致性还是需要保证的。 缓存污染问题通常是由于代码开发不规范导致的，比如更新缓存数据后，由于某些原因，比如业务发生异常回滚，导致数据没有写入数据库中，这时缓存中数据是新的，但是数据库还是就数据。 为了尽可能保证缓存数据的一致性，业内总结了很多更新缓存的设计模式，包括 Cache Aside、Read/Write Through、Write Behind Caching 等等，其中最常用的是 Cache Aside 模式，因为它最简单、成本最低。主要内容可以概括为以下两点： 读数据时，首先读缓存，没有缓存，再度数据源，然后将数据写入缓存，再响应请求 写数据时，先写数据源，然后失效缓存 写数据时，这里要注意两点。 一个是先后顺序一定是先数据源，再缓存。如果先失效缓存，再更新数据源，一定存在一段时间内缓存已经删除完毕，数据源还未更新。此时如果有读请求进来，无法命中缓存，就会到达数据源中。 此时读到的还是旧数据，随后又会写到缓存中。等数据更新完成后，就出现了缓存中是旧数据，数据源是新数据，两者数据不一致的情况。 二是应当失效缓存，而不是更新缓存。因为如果是更新缓存，更新过程中数据源又被其它请求修改，缓存要面临多次赋值的复杂时序问题。如果是失效缓存，则无论这个过程中数据源更新了多少次，都不会产生影响。 当然，有一种情况下 Cache Aside 模式也会导致数据不一致，就是如果某个数据是从未被缓存过的，或是恰好超期失效，或是恰好因为更新被失效，读请求就会达到数据源中。如果对数据源的又一个写操作正好发生在查询请求之后，结果回填到缓存前，也会出现缓存中数据和数据源不一致的情况。 相对而言，这种缓存不一致出现的条件更为苛刻一点。通过设置合理的过期时间，可以控制这种情况下的最长影响时间。 通常情况下，Cache Aside 模式依然是一种低成本更新缓存，且能够获得相对可靠结果的解决方案。 BigKeystring 类型超过 10KB，hash、list、set、zset 元素个数超过 5000，可以认为是 big key，可能导致 Redis 性能下降。 BigKey 的产生可能有下面这些原因： 未正确使用 Redis，如使用 String 类型的 key 存放大体积二进制文件型数据 业务规划不足，没有对 key 中的成员进行合理的拆分，造成个别 key 中的成员数量过多 未定期清理无效数据，造成如 HASH 类型 key 中的成员持续不断地增加 服务发生异常，如使用 LIST 类型 key 的业务消费侧发生代码故障，造成对应key 的成员只增不减 BigKey 可能导致以下问题： 大量占用内存，引发操作阻塞或重要的 key被逐出，甚至引发内存溢出 集群架构下，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡 命令执行效率下降，如 lrange、hgetall 等时间复杂度为 O(n) 的命令 对 BigKey 执行读请求，会使 Redis 实例的带宽被占满，影响服务性能 对 BigKey 执行删除操作，易造成主库较长时间的阻塞，进而可能引发同步中断或主从切换 BigKey 需要更多的网络带宽来传输可能导致网路阻塞，特别是在进行备份、复制或者集群间数据同步时 如何定位 BigKey： 通过 redis-cli 的 bigkeys 参数查找 BigKey 通过 Redis 内置命令 DEBUG OBJECT、MEMORY USAGESTRLEN、LLEN 等对目标 Key 进行分析 使用第三方工具redis-rdb-tools，使用过程中会先使用 bgsave 命令dump一个rdb 镜像，然后对这个镜像进行分析 我们可以参考以下几种方案来解决 BigKey 的问题。 第一，尝试压缩 value。 第二，将 BigKey 拆分成多个小 key。 第三，对 BigKey 进行清理，迁移到其它更适合的存储中。 第四，对集合中的过期数据进行定期清理。 第五，删除 BigKey 时，使用 redis4.0 新特性，非阻塞删除。 HotKeyHotKey 是指 Redis 中访问频率特别高的 key。在秒杀、爆款商品、爆款新闻等场景中经常会出现 HotKey，可能导致以下问题： 占用 Redis server 端大量的 CPU 资源，导致整体性能下降 如果是集群架构，会产生访问倾斜，某个内存分片被大量访问，可能导致该分片出现连接数耗尽、性能下降等问题 增加网络流量，可能导致网路阻塞 出现缓存击穿现象，导致数据库压力突增，影响其它业务 访问量超出 Redis server 上限，导致服务崩溃，进一步导致缓存雪崩 如何定位 HotKey： 通过 redis-cli 的 hotkeys 参数查找 HotKey 在业务层增加相应的代码对 Redis 的访问进行监控分析 通过 MONITOR 命令找出 HotKey 我们可以参考以下几种方案来解决 HotKey 的问题。 第一，可以增加本地缓存，来降低 HotKey 的访问频率。不过这种方案会面临缓存不一致、消耗本地内存的问题。 第二，对 HotKey 进行复制，比如将 HotKey foo 复制出 3 个内容完全一样的 Key 并名为 foo2、foo3、foo4。该方案的缺点在于需要联动修改代码，同时也有数据一致性的问题。 第三，在客户端和 Redis server 间接入 proxy 层，通过 proxy 实现读写分离以及读流量在多个从节点间的负载均衡。在请求量极大的场景下，读写分离架构会产生不可避免的延迟，此时会有读取到脏数据的问题。 第四，同样是接入 proxy 层，但 proxy 在这里承担缓存 HotKey 查询结果的职责。类似方案一，改进的地方是对业务层是透明的。 总结本文总结了 Redis 作为缓存的常见问题及解决方案，不同的业务场景下可能会面临不同的问题，可以采取的方案也不尽相同。可以遵循一个原则进行选择，“能满足需求的前提下，最简单的系统就是最好的系统”。 参考 分布式缓存如何与本地缓存配合，提高系统性能？ 发现并处理Redis的大Key和热Key Understanding and Solving HotKey and BigKey issues in Redis Redis Hotspot Key Discovery and Common Solutions","link":"/2023/11/13/redis-problem/"},{"title":"保证缓存最终一致性的方案有哪些？","text":"随着业务数据的增多和业务流量的增长，如果只依赖数据库来承接所有的流量，服务的性能和稳定性都会面临风险。由于互联网业务往往是读多写少的场景，所以非常适合增加缓存来提升系统的响应能力，同时降低数据库的访问压力。 使用缓存在带来好处的同时，也带来了数据一致性的问题。针对这个问题，业界已经总结了几种常用的更新缓存的设计模式，来保证缓存和数据库的最终一致性。注意这里是最终一致性，因为使用的缓存的大部分场景，最终一致性足以满足业务需求，很少有需要强一致性的场景。 接下来我们会分别介绍这几种更新缓存的设计模式。 Cache-AsideCache-Aside 叫做旁路缓存模式。下图描述了这种模式的处理流程。处理读请求时，首先查询缓存，如果缓存数据有效，则直接返回，否则查询数据库，然后将数据更新到缓存中，再返回数据；处理写请求时，首先更新数据库，然后删除缓存。 Cahce-Aside 模式读写请求处理流程 读请求的过程很容易理解，关于写请求，可能会有这么几个疑问。 问题1：为什么是先操作数据库，再操作缓？先后顺序一定是先数据源，再缓存，这是非常重要的一点。因为如果先删除缓存，再更新数据源，则会存在一段时间内缓存已经删除完毕，数据源还未更新。此时如果有读请求进来，无法命中缓存，就会到达数据源中。 此时读到的还是旧数据，随后又会写到缓存中。等数据更新完成后，就出现了缓存中是旧数据，数据源是新数据，两者数据不一致的情况。下图描述了这种场景。 关于延时双删 为了解决先删除缓存，再更新数据库这种方案导致的问题，网上的资料经常看到一种叫做“延时双删”的方案。即在更新数据库后，延迟一段时间再次删除缓存。显然，再次删除缓存的操作应该在读请求更新缓存后，所以延迟的时间一般要比读请求的耗时稍大一些，通常可以采用 sleep 或者延迟队列实现。 我个人认为这种方案不具有应用价值。一方面是延时的时间很难界定；另一个更重要的原因是再更新数据库之前删除缓存并没有带来任何好处，反而要为此采用再次删除的操作作为补偿机制，那我们直接不要在更新数据前删除缓存就好了。 延时双删 问题2：为什么是删除缓存，是否能直接更新缓存呢？1）因为如果是更新缓存，更新过程中数据源又被其它请求修改，缓存要面临多次赋值的复杂时序问题，可能会导致数据不一致。下图描述了这种场景。而删除操作是幂等的，不会出现这种情况。 2）如果缓存是经过大量的计算得到的，在写数据时去更新缓存可能是一笔不小的开销，如果更新缓存后没有来的及使用，缓存就再次被更新（这被称为缓存扰动），则会造成资源的浪费；读数据时更新缓存则符合懒加载的思想。 问题3：Cache-Aside 模式一定能保证数据一致性吗？不一定，有可能出现数据不一致的情况。 1）当读请求查询缓存时，如果数据从未被缓存过或者缓存正好因超期而失效，当从数据库查询数据后，更新到缓存前，如果有写请求在此期间执行完成，则会导致缓存中的数据被旧数据覆盖。执行过程如下图所示： 这种情况发生要满足下面两个条件： 数据从未被缓存过或者刚好失效 读写并发执行，读请求查询数据库的执行要早于写请求更新数据库开始，但读请求执行完成要晚于写请求 所以这种不一致的场景产生的条件还是比较严格的，在实际生产环境中出现的可能很小。 2）另外，如果写请求删除缓存失败，也会导致缓存中数据落后于数据库中的数据。针对这种情况，通常可以采取以下几种机制。 缓存设置过期时间 通常缓存都会设置一个过期时间，如果出现不一致，最多持续时长为缓存的过期时间。如果业务上可以接受，这是代价最小的解决方案； 删除重试机制 正如前面提到的，删除操作是幂等的，所以很方便可以进行重试，但如何重试是值得考虑的一个问题； 首先同步重试会影响请求的性能，异步重试可以通过消息队列来实现，比如删除失败后写一条消息到消息队列中，或者更新数据库后直接写一条消息到队列中，通过消息队列执行删除操作，并自动进行重试。 这种方案的问题是为原本很简单的操作引入了太大的复杂性，非必要不建议采取，而且对缓存系统进行重试也要慎重对待，当系统出现问题时，重试导致的流量激增往往会导致问题进一步恶化。 利用事务 还有一种方案是将更新数据库的操作和删除缓存的操作放到同一个事务中，删除失败时回滚事务。 这种方案实现起来很简单，但不建议使用，原因如下：1）在事务操作中增加一次网络调用，会延长事务的持续时间，相当于降低了数据库的并发性能2）缓存系统的问题会引起连锁反应，导致数据库大量操作回滚，本来只是数据一致性的问题，现在则会影响到整个系统的可用性3）由于网络原因，出现删除缓存成功，但返回客户端网络异常的情况，导致数据库操作会滚，但缓存实际已经失效了，可能导致更多的请求因缓存缺失而访问数据库，给数据库带来压力 Read-ThroughRead-Through 叫做读穿透模式，和 Cache-Aside 的读请求流程基本一样，不同的是多了一个访问控制层。问控制层封装了缓存和数据库交互的逻辑，业务层只和访问控制层进行交互，实现更加简洁，良好的封装性也让程序更容易维护和移植。 在我看来，这种方案相比 Cache-Aside 只是更加强调了代码实现上的封装和解耦，核心思路是完全一样的。 Write-ThroughWrite-Through 叫做直写模式，它也提供了访问控制层，和 Cache-Aside 的区别是，Write-Through 更新数据库后会直接更新缓存，而不是删除缓存。 当然这里如果是先更新缓存，再更新数据库也是可以的。但无论如何，更新缓存而不是删除缓存，就会面临前面提到的两个问题： 并发更新时缓存要面临多次赋值的复杂时序问题 对写请求的性能影响及缓存扰动问题 第一个问题是必须要解决的，典型的方案是通过分布式锁来保证两个操作的原子性，当然不可避免地会影响系统的并发处理能力。 一个简化的方式是将两个操作都放到数据库的事务中执行，这种方案的问题前面也分析过两点，这里还要再提一点，因为 Redis 并不支持事务，所以极端情况下可能出现 Redis 更新成功，但 MySQL 事务回滚的情况（执行 commit 命令时发生异常）。 关于第二个问题，虽然对写请求的性能有影响，但因为直接更新缓存，读取时就可以快速地从缓存中获取数据。所以 Write-Through 更加适合对读取操作要求较高性能要求的场景。 另外，在 Write-Through 模式下，不管是先更新缓存还是先更新数据库，都存在更新缓存或者更新数据库失败的情况，前面提到的重试机制这里也是奏效的。 Write-BehindWrite-Behind 叫做异步回写模式。和 Read-Through/Write-Through 具有类似的访问控制层，不同的是 Write-Behind 处理写请求时只更新缓存而不更新数据库。对数据库的更新，通过异步批量更新的方式进行，批量写入的时间点可以在数据库负载较低的时间进行。 Write-Behind 模式减轻了数据库压力，写请求延迟低，可以支持更高的吞吐量。但是数据一致性较弱，缓存数据未写入数据库时，直接从数据库中查到的是旧数据。同时对缓存系统的压力比较大，缓存宕机回导致数据丢失，所以要做好缓存系统的高可用。所以，Write-Behind 更加适合大量写操作的场景，比如电商秒杀场景中的减库存。 Write-Around对于非核心业务场景，可以选择在 Cache-Aside 模式下增加缓存过期时间，在写请求中仅仅更新数据库，不做任何删除或者更新缓存的操作，缓存仅能通过过期时间失效。 这种方案实现简单，但数据一致性较差，可能导致用户体验较差，要慎重选择。 基于数据库日志（ MySQL binlog ）增量订阅和消费除了上面介绍的几种缓存更新模式，还有一种方案，就是订阅 MySQL binlog，将数据库更新事件写入 MQ 中，然后在消费逻辑中删除相应的的缓存。 这种方案的优点是删除缓存的逻辑和业务进行了解耦，并且消息队列天然具备重试能力。不过要注意如果 binlog 消费存在较大延迟，在此期间从缓存读取到是旧数据。 因为消费 binlog 不存在并发更新的复杂时序问题，所以这里直接更新缓存也是可以的。但是当读请求正好触发更新缓存时，和 binlog 触发的更新缓存之间也会出现并发更新的时序问题，虽然这种场景出现的概率很小，但还是更加推荐删除缓存而不是更新。 总结以上是业界常用的几种解决缓存一致性的方案，其中，Cache-Aside 模式是以低成本更新缓存，并且获得相对可靠结果的解决方案，适用于大部分场景；另外对于大量写操作的场景，考虑使用 Write-Behind 模式；如果业务中有成熟的 binlog 增量订阅和消费机制，则可以考虑基于 binlog 来维护缓存的一致性。 参考 浅谈缓存最终一致性的解决方案 分布式缓存如何与本地缓存配合，提高系统性能？","link":"/2023/12/19/cache-consistency/"},{"title":"TCP 是如何保证可靠性的？","text":"","link":"/2023/12/19/tcp-reliability/"},{"title":"socket 通信中可能发生哪些异常","text":"socket 是网络编程的基础，业务开发中常用的 HttpClinet、RPC 框架等底层网络通信基础都离不开 socket，在使用这些框架的时候，可能会遇到 connect refused、connect reset by peer 等异常情况，这些异常的含义很容易理解。 但是当发生这些异常的时候，socket 的一些行为细节，更近一步的，TCP 协议中的发生了什么，可能就不是那么直观清晰了。 所以我专门针对 socket 编程中可能出现的异常进行了调研，针对不同的异常情况，给出了 C 语言 socket 编程代码示例，并分析了发生对应情况时 TCP 协议层的具体动作。 拒绝连接异常拒绝连接异常就是服务端拒绝了客户端的连接，在如下这个代码示例中，当我们试图连接到一个本地未监听的端口时，就会收到这样的一个异常信息。 根据 ip 地址和 端口，建立 TCP 连接： 1234567891011121314151617181920212223242526int tcp_client(const char *address, int port) { int socket_fd; socket_fd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_port = htons(port); inet_pton(AF_INET, address, &amp;server_addr.sin_addr); socklen_t server_len = sizeof(server_addr); // 调用 connect 函数建立连接 int connect_rt = connect(socket_fd, (struct sockaddr *) &amp;server_addr, server_len); if (connect_rt &lt; 0) { // 如果连接发生异常，打印错误日志 error(1, errno, &quot;connect failed &quot;); } return socket_fd;}int main(int argc, char** argv) { char *ip = argv[1]; int port = atoi(argv[2]); int socket_fd = tcp_client(ip, port);} 不启动服务端的情况下，尝试建立连接，终端输出信息如下： 1connect failed : Connection refused (61) 可以看到当发生 Connection refused 异常时，socket 层是由 connect 函数返回了对应的错误码，那么 TCP 协议层发生了什么呢？ 我们知道 TCP 建立连接时需要进行 3 次握手，客户端首先发送 sync 报文段，如果报文段到达了目标主机，但是发现目标端口上没有正在监听的服务，则会发出 RST 报文段作为回复，拒绝此次连接。客户端收到 RST 回答后，通过 connect 函数报告这一错误。 产生 RST 的情况由如下 3 种： sync 报文段到达，但目标端口没有正在监听的服务（如上所述） TCP 想取消一个已有连接 TCP 接收到一个根本不存在的连接上的报文段 连接超时异常还是上一小节的代码示例，如果在建立连接时，指定了一个无法连接的 ip 地址，比如和本机不在同一个局域网的私有 ip 地址，终端会输出如下错误信息： 1connect failed : Operation timed out (60) connect 函数默认情况下是阻塞调用，直到连接建立成功或者报告错误。如果客户端发出的 SYN 包没有任何响应，最终会返回 TIMEOUT 错误。 Linux 下默认的超时时间是 75s，实际应用中这个超时时间是不能接受的，所以在实际的网络通信中我们通常会IO多路复用的方式来建立连接，在调用 select 或者 poll 或者 epoll 函数时指定超时时间。 发生这种情况代表目标主机不可达，可能是 ip 地址写错，或者是网络出现故障。但有时我们会收到明确的 destination unreachable 错误，表示客户端和服务器端路由不通，这是因为客户端收到了路由器或者防火墙报告的 icmp 差错报文。 目标不可达 ICMP 类型 3 表示“Destination Unreachable”（目标不可达），而类型 3 中的不同代码用于指示导致目标不可达的具体原因，常见的代码有如下几种： Code 0: Net Unreachable（网络不可达） Code 1: Host Unreachable（主机不可达） Code 2: Protocol Unreachable（协议不可达） Code 3: Port Unreachable（端口不可达） 所以，当端口不可达时，客户端除了收到 RST 回答，还可能收到 ICMP 差错报文，这可能会因不同的网络设备、操作系统或防火墙设置而有所不同。 连接断开异常上述两个异常是建立连接时可能遇到的，那么当连接建立成功后，因为某种原因连接断开了，会发生什么呢？ socket 中通常只有两种方式来感知 TCP 链路的异常中断，一种是以 read 为核心的读操作，一种是以 write 为核心的写操作。下面我们看下不同场景下通过读写操作来感知 TCP 连接的异常。 对端有 FIN 包发出read 直接感知 FIN 包在正常的连接断开过程中，对端会发送 FIN 报文段，客户端通过 read 接口感知到后，会做出相应的处理，比如关闭连接，释放连接资源。 服务端程序如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859int tcp_server(int port) { int listenfd; listenfd = socket(AF_INET, SOCK_STREAM, 0); struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); server_addr.sin_port = htons(port); int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, sizeof(on)); int rt1 = bind(listenfd, (struct sockaddr *) &amp;server_addr, sizeof(server_addr)); if (rt1 &lt; 0) { error(1, errno, &quot;bind failed &quot;); } int rt2 = listen(listenfd, LISTENQ); if (rt2 &lt; 0) { error(1, errno, &quot;listen failed &quot;); } int connfd; struct sockaddr_in client_addr; socklen_t client_len = sizeof(client_addr); if ((connfd = accept(listenfd, (struct sockaddr *) &amp;client_addr, &amp;client_len)) &lt; 0) { error(1, errno, &quot;bind failed &quot;); } return connfd;}int main(int argc, char **argv) { int connfd; char buf[1024]; connfd = tcp_server(SERV_PORT); for (;;) { int n = read(connfd, buf, 1024); if (n &lt; 0) { error(1, errno, &quot;error read&quot;); } else if (n == 0) { error(1, 0, &quot;client closed \\n&quot;); } sleep(5); ssize_t write_nc = write(connfd, buf, n); printf(&quot;send bytes: %zd \\n&quot;, write_nc); if (write_nc &lt; 0) { error(1, errno, &quot;error write&quot;); } } exit(0);} 客户端程序如下： 1234567891011121314151617int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int rc; while (1) { rc = read(socket_fd, buf, sizeof(buf)); if (rc &lt; 0) error(1, errno, &quot;read failed&quot;); else if (rc == 0) error(1, 0, &quot;peer connection closed\\n&quot;); else fputs(buf, stdout); } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，客户端终端输出如下： 1peer connection closed 因为阻塞的 read 操作读取到了 FIN 包后返回值为 0，客户端程序感知到 FIN 包后，执行正常退出逻辑。 通过 write 产生 RST，read 调用感知 RST客户端程序如下： 123456789101112131415161718192021222324int main(int argc, char **argv) { int connfd; char buf[1024]; connfd = tcp_server(SERV_PORT); for (;;) { int n = read(connfd, buf, 1024); if (n &lt; 0) { error(1, errno, &quot;error read&quot;); } else if (n == 0) { error(1, 0, &quot;client closed \\n&quot;); } sleep(5); ssize_t write_nc = write(connfd, buf, n); printf(&quot;send bytes: %zd \\n&quot;, write_nc); if (write_nc &lt; 0) { error(1, errno, &quot;error write&quot;); } } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，然后在客户端终端输入“Hello World”，回车后会看到如下错误信息： 1read failed: Connection reset by peer (54) 客户端程序启动后，会阻塞在从标准输入读取数据的 fgets 方法上，因为无法感知到连接已经断开。 当从标准输入获取数据后，会将数据通过 socket 发送给服务端，因为服务端进程已经不存在，所以会返回一个 RST 包，接下来客户端的 read 调用感知到 RST，会返回异常信息，表明连接已断开。 注意 以上实验结果是在 MacOS 14.2.1 上进行的，在 Linux 系统上，这里的 read 调用可能读取到服务端程序关闭时发出的 FIN 包，从而正常关闭，而不是返回 RST 错误。说明不同系统内核中的的 TCP 协议实现可能略有不同。 向一个以关闭连接连续写，导致 SIGPIPE客户端程序如下： 123456789101112131415161718192021static void sig_pipe(int signo) { printf(&quot;SIGPIPE(%d)\\n&quot;, signo);}int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int len; int rc; signal(SIGPIPE, sig_pipe); while (fgets(buf, sizeof(buf), stdin) != NULL) { len = strlen(buf); rc = write(socket_fd, buf, len); if (rc &lt; 0) error(1, errno, &quot;write failed&quot;); } exit(0);} 分别启动服务端和客户端后，kill 掉服务端进程，然后在客户端终端连续输入数据，第二次回车后会看到如下错误信息： 12SIGPIPE(13)write failed: Broken pipe (32) 和前一个例子类似，当向一个已经关闭的连接发送数据时，会得到 RST 回复。如果客户端再次向这个连接发送数据，则会收到一个 SIGPIPE 信号。如果不捕捉这个信号，应用程序会在毫无征兆的情况下直接退出。 因为我们在程序中捕获了 SIGPIPE 信号，所以可以看到两行输出，第一行是对 SIGPIPE 信号的处理逻辑打印的通知信息，第二行是 write 调用的返回的错误信息。 注意： 在某些 Linux 版本中，第二次 write 操作不会收到 SIGPIPE 信号，而是返回 RST 错误信息。 对端无 FIN 包网络中断导致对端没有 FIN 包当网络中断时，如果网络中其他设备，比如路由器发出了 ICMP 差错报文，说明网络或者主机不可达，这是 read 或者 write 调用会返回 unreachable 错误。 如果没有 ICMP 报文，TCP 并不能及时感知到异常信息。如果此时程序阻塞在 read 方法上，则将无法回复运行，所以通常我们通过设置超时时间来避免这个问题，具体方式下一节分析读取超时异常时会介绍。 如果此时程序首先调用 write 发送了数据，然后阻塞在 read 调用上，系统的 TCP 协议栈会不断尝试将发送缓冲区的数据发送出去，大概在重传 12 次、合计时间约为 9 分钟之后，协议栈会标识该连接异常，这时，阻塞的 read 调用会返回一条 TIMEOUT 错误信息。如果程序继续 wirite 数据，则会收到一个 SIGPIPE 信号。 系统崩溃导致对端没有 FIN 包这种情况和网络中断的情况是类似的，在没有 ICMP 报文的情况下，只能通过 read 或者 write 感知异常。 不同的地方在于，如果系统崩溃之后重新启动，重传的数据到达重启后的系统后，因为系统中没有该连接信息，会返回一个 RST 包。 如果客户端阻塞在 read 调用上，会立即返回 connect reset 错误；如果是 write 调用，也会立即失败，并收到一个 SIGPIPE 信号。 读取超时异常前面提到过，服务端可能因为各种原因断开连接后，没有发出 FIN 包。如果是阻塞套接字，会一直阻塞在 read 调用上，没有办法感知套接字的异常。 所以我们通常会给套接字的 read 操作设置超时。可以说，读取超时异常是上层应用最常见的网络异常之一。 客户端代码如下： 1234567891011121314151617181920212223242526272829int main(int argc, char** argv) { int socket_fd = tcp_client(&quot;localhost&quot;, SERV_PORT); char buf[129]; int len; int rc; // socket read 超时设置为 1s struct timeval tv; tv.tv_sec = 1; tv.tv_usec = 0; setsockopt(socket_fd, SOL_SOCKET, SO_RCVTIMEO, (const char *) &amp;tv, sizeof tv); while (fgets(buf, sizeof(buf), stdin) != NULL) { len = strlen(buf); rc = write(socket_fd, buf, len); if (rc &lt; 0) error(1, errno, &quot;write failed&quot;); sleep(3); rc = read(socket_fd, buf, sizeof(buf)); if (rc &lt; 0) error(1, errno, &quot;read failed&quot;); else if (rc == 0) error(1, 0, &quot;peer connection closed\\n&quot;); else fputs(buf, stdout); } exit(0);} 分别启动服务端和客户端后，在客户端终端输入数据，1s 后会看到如下错误信息： 1read failed: Resource temporarily unavailable (35) 因为客户端程序中，socket 超时时间设置为 1s，而服务端发送数据前 sleep 了 5s，所以这里 read 函数返回读取超时错误信息。 总结本文中总结了 socket 编程可能遇到的几种常见异常场景，并结合 TCP 协议进行了分析，其中，当服务端连接意外中断时，客户端对连接异常信息的检测，可能因不同的条件而产生 Connection Reset、Broken Pipe 等不同的错误信息。读完本篇文章后，如果应用层遇到了类似的问题，我想可以有更加清晰的理解和排查思路。 另外，文章中涉及的代码已经上传到了 githug，地址如下：https://github.com/qinjianmin/socket-exception。 参考网络编程实战","link":"/2024/01/07/socket-exception/"},{"title":"书单","text":"","link":"/2023/12/25/book-list/"},{"title":"深入理解 Java 中的类加载机制","text":"","link":"/2024/01/08/class-loader/"},{"title":"记一次接口性能优化的实践经历","text":"很多时候，我们进行 JVM 调优或者服务性能优化的难点在于定位问题的根因。因为大部分问题我们都可以通过各种搜索引擎找到类似的场景，然后用同样的手段尝试去解决。所以相比解决方案，更重要的其实是如何从现象出发，去排查问题、定位原因。 我在工作中有过两次服务性能问题排查的经历，最终发现都和 JVM 有着密切的关系，下面我会分别进行详细的介绍。 一方面是这两个问题都是比较典型的 JVM 问题，大家遇到类似的场景可以参考。另一面，排查问题的过程非常值得总结，尤其是第一个例子中，经历了比较多的曲折，也让我对类似的复杂的问题的排查方式有了一定的思考。 优化案例问题1：GC promotion failed问题2：OOM总结","link":"/2024/02/05/jvm-problem/"},{"title":"如何用 Java NIO 实现一个非阻塞服务器？","text":"","link":"/2024/01/18/java-nio-server/"},{"title":"HTTP2 和 HTTP1.1 究竟有什么差别？","text":"","link":"/2024/01/11/http2/"},{"title":"业务开发中如何应用设计原则、思想提升代码质量","text":"","link":"/2024/02/05/ddd/"},{"title":"深入理解 Java 线程","text":"线程创建方式Java 中创建线程有两种方式。第一种是定义 Thread 类的一个子类，在子类中重写 run 方法。然后创建子类实例后调用子类的 start 方法。示例如下： 1234567891011121314class PrimeThread extends Thread { long minPrime; PrimeThread(long minPrime) { this.minPrime = minPrime; } public void run() { // compute primes larger than minPrime . . . }} PrimeThread p = new PrimeThread(143); p.start(); 另一种创建线程的方式是定义 Runnable 接口的实现类，并实现 run 方法。然后将这个实现类的实例作为构造 Thread 对象的参数，然后调用 Thread 对象的 start 方法。示例如下： 1234567891011121314class PrimeRun implements Runnable { long minPrime; PrimeRun(long minPrime) { this.minPrime = minPrime; } public void run() { // compute primes larger than minPrime . . . }}PrimeRun p = new PrimeRun(143);new Thread(p).start(); 了解了上面的内容，可以说就已经掌握了 Java 中线程的使用方式。接下来介绍下线程的生命周期。 线程生命周期五态模型通用的线程生命周期可以用“五态模型”来描述。 初始状态线程已经创建，但是还不允许分配 CPU 执行。这个状态是编程语言特特有的，这里的被创建，指的是在编程语言层面被创建，在操作系统层，真正的线程还没有创建 可运行状态可以被分配 CPU 执行，这种状态下，真正的操作系统线程已经被创建 运行状态被分配到 CPU 的线程状态转换为运行状态 休眠状态运行状态的线程如果调用一个阻塞的 API（利用以阻塞的方式读取文件）或者等待某个事件（例如条件变量），那么线程转换为休眠状态并释放 CPU 的使用权，休眠状态的线程永远无法获取 CPU 使用权。当等待的事件出现后，线程会从休眠状态转变为可运行状态。 终止状态当线程执行完或者出现异常，线程进入终止状态。终止状态无法切换为任何其它状态，进入终止状态就意味着线程的生命周期结束了。 Java 中的线程的生命周期Java 语言中线程共有六种状态。 NEW（初始化状态） RUNNABLE（可运行 / 运行状态） BLOCKED（阻塞状态） WAITING（无时限等待） TIMED_WAITING（有时限等待） TERMINATED（终止状态） 相比于五态模型，Java 语言里把可运行状态和运行状态合并了，这两个状态在操作系统调度层面有用，而 JVM 层面不关心这两个状态，因为 JVM 把线程调度交给操作系统处理了。 除此以外，Java 语言中细化了休眠状态。Java 线程中的 BLOCKED、WAITING、TIMED_WAITING 都对应操作系统层面的休眠状态。 Java 中线程状态转换1）RUNNABLE 和 BLOCKED 的转换 线程等待 synchronized 的隐式锁时 2）RUNNABLE 和 WAITING 的转换 获得 synchronized 隐式锁的线程，调用无参数的 Object.wait() 方法 调用无参数的 Thread.join() 方法 调用 LockSupport.park() 方法 3）RUNNABLE 和 TIMED_WAITING 的转换 调用带超时参数的 Thread.sleep(long millis) 方法 获得 synchronized 隐式锁的线程，调用带超时参数的 Object.wait(long timeout) 方法 调用带超时参数的 Thread.join(long millis) 方法 调用带超时参数的 LockSupport.parkNanos(Object blocker, long deadline) 方法 调用带超时参数的 LockSupport.parkUntil(Object blocker, long deadline) 方法 4）NEW 到 RUNNABLE 状态 调用线程对象的 start() 方法 5）RUNNABLE 到 TERMINATED 状态 执行完 run() 方法 执行 run() 方法的时候异常抛出 需要注意的是，当线程调用阻塞式 API 时，是否会转换到 BLOCKED 状态呢？ 在操作系统层面，线程是会转换到休眠状态的，但是在 JVM 层面，Java 线程的状态不会发生变化，也就是说 Java 线程的状态会依然保持 RUNNABLE 状态。JVM 层面并不关心操作系统调度相关的状态，因为在 JVM 看来，等待 CPU 使用权（操作系统层面此时处于可执行状态）与等待 I/O（操作系统层面此时处于休眠状态）没有区别，都是在等待某个资源，所以都归入了 RUNNABLE 状态。 可见 Java 线程状态只是 JVM 的内部定义，和操作系统线程状态没有严格的对应关系，这里的 RUNNABLE 就对应了操作系统中的可运行状态、运行状态和部分休眠状态。 了解完 Java 线程状态，可能会有这样的疑问，为什么单单只有 synchronized 获取锁阻塞时，状态是 BLOCKED，而 JUC 中的锁阻塞时、或者阻塞在条件变量上时，状态是 WAITING 呢？ 因为在最初的设计 synchronized 时，BLOCKED 表示锁阻塞，WAITING 表示条件变量阻塞，这样区分开是可以理解的，但 JUC 中提供阻塞线程的方法时，底层都是调用的 Unsafe 类的 park 方法，实现 park 方式时，就只能选择一种，JVM 就任选了其中之一。 接下来，我们结合 Thread 类源码，看下其中关键方法的实现。 构造方法首先是构造方法，Thread 类中提供了多个重载的构造方法，可以设置线程的线程组、任务、名称、栈深度等，最终会调用到 init 方法初始化参数。 12345private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { ...} ThreadGroup g 线程组，用于批量管理线程。每个线程都属于一个线程组，如果没有指定，默认会将创建线程的线程的线程组设置为新建的这个线程的线程组 Runnable target 线程执行的任务。前面介绍过两种创建线程的方式，其中之一就是将 Runnable 的实现类对象作为创建线程的参数。Thread 类本身实现了 Runnable 接口，线程启动后，会执行 Thread 类的 run 方法。run 方法的默认实现就是，如果 target 不为 null，则调用 target 的 run 方法 12345public void run() { if (target != null) { target.run(); }} String name 线程名称。如果没有指定，默认会使用如下形式。 123456public Thread() { init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);}private static synchronized int nextThreadNum() { return threadInitNumber++;} long stackSize 线程栈深度。如果是 0，表示创建时没有指定；即使指定了，能发挥什么作用取决于虚拟机的具体实现，一些虚拟机会忽略它。 线程中断1234567891011121314public void interrupt() { if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) { Interruptible b = blocker; if (b != null) { interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; } } interrupt0();} 可以从以下几个方面来理解线程中断。 1）谁有权利中断一个线程 线程中断自身肯定是被允许的，否则会通过 checkAccess 方法来检查权限。 2）中断的效果 如果线程不是 alive 状态（isAlive() 方法返回 true，表示线程处于 alive 状态，也就是说线程已经开始，但还没有结束），调用这个方法没有任何影响 如果线程阻塞在 wait()、wait(long)、wait(long, int)、join()、join(long)、join(long, int)、sleep(long) 或者 sleep(long, int) 方法上，将会清除中断状态并收到 InterruptedException 如果线程阻塞在 InterruptibleChannel 的 I/O 操作上，那么这个通道将会被关闭，设置线程中断状态，并且线程会收到 java.nio.channels.ClosedByInterruptException 如果线程阻塞在 java.nio.channels.Selector 上，将会设置线程中断状态，然后立即从 selection 操作返回，返回值可能是一个非零值，就像调用wakeup 方法一样 如果不是以上这些情况，会设置线程的中断状态 3）检查线程中断 当线程发生中断时，除了上面提到的几种抛出异常的场景外，我们需要通过轮询中断状态来感知中断的发生，也就是在合适的时机（通常放在循环的开始处）去判断线程的中断状态，然后做对应的操作（抛出异常或直接返回）。 Thread 类中提供了以下两个检查中断状态的的方法，他们的区别在于前者是静态方法切会清除中断状态，后者是实例方法且不会清楚中断状态。 1234567public static boolean interrupted() { return currentThread().isInterrupted(true);}public boolean isInterrupted() { return isInterrupted(false);} 4）中断的作用 中断机制提供了一种线程通知的机制，可以用来唤醒阻塞的线程、终止线程任务等。中断只是给线程发出一个通知，其效果是依赖线程自身的中断检测逻辑的，也就是说中断后进行什么操作是由线程自身决定的。相比 suspend()、stop() 等方式更加的温和，不会出现死锁等问题。关于 suspend()、stop() 等方法的问题后文中有详细介绍。 Thread 类常用方法 （static）yeild() yeild() 提示 JVM 线程调度器，当前线程想要让出 CPU 的使用权，但是线程调度器可以忽略这一提示。 这是一个启发式的尝试，避免某个线程对 CPU 的过度使用。它的使用应与详细的分析和基准测试相结合，以确保它实际上具有预期的效果。 实际上很少有合适的场合会使用这个方法。它通常被用于调试或者测试，帮助复现多线程中的 bug。在实现并发工具时这个方法可能很有用， java.util.concurrent.locks 包中的很多类用到了它。 （static）sleep(long)、sleep(long, int) 使正在运行的线程暂时停止执行一段时间（受系统定时器和调度器的精度和准确性影响）。sleep 的线程并不会释放它持有的锁。 join()、join(long)、join(long, int) 等待线程执行结束。底层实现实际上是循环检查 isAlive 方法，不满足条件时，调用线程对象的 wait 方法阻塞调用方，线程终止时会调用 notifyAll 方法唤醒阻塞的线程。 123456789101112131415161718192021222324public final synchronized void join(long millis)throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) { throw new IllegalArgumentException(&quot;timeout value is negative&quot;); } if (millis == 0) { while (isAlive()) { wait(0); } } else { while (isAlive()) { long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } }} Thread 类中的过时方法 suspend() 和 resume() suspend 用于挂起一个线程，与之对应的，resume 方法用于恢复挂起的线程。 之所以被弃用，因为这两个方法可能导致线程死锁。挂起的线程不会释放锁资源，如果被挂起的线程持有某个锁，而计划执行 resume 方法的线程需要首先获取这个锁资源，就发生了死锁。 stop() stop 方法使线程抛出 ThreadDeath 异常，导致线程直接终止。如果线程还没有开始就调用了 stop 方法，那么线程开始后会立刻终止。通常应用程序不应该捕获 ThreadDeath 异常，除非想要在线程终止前做一些额外的清理操作，如果捕获了 ThreadDeath，应该重新抛出这个异常，以确保线程能最终终止。 这个方法之所以被弃用，因为它是不安全的。调用 stop 方法后，线程会释放所有持有的锁，这些锁保护的资源可能正处于不一致的状态，这些损坏的对象将对其它线程可见，从而导致不可预料的行为。使用 stop 方法的场景，可以使用中断通知来完成，执行任务的线程检查到中断状态后，能够完成收尾工作，再停止运行。 异常处理接下来，介绍下 Java 线程中的异常处理机制。 当线程因为未捕获异常终止时，虚拟机会通过线程的 getUncaughtExceptionHandler 方法获取线程的 uncaughtExceptionHandler，并调用其 uncaughtException 方法来处理异常； 如果没有显示设置 uncaughtExceptionHandler，getUncaughtExceptionHandler 方法会返回线程的 ThreadGroup 对象； ThreadGroup 的 uncaughtException 方法的实现逻辑为： 如果存在父线程组，调用父线程组的 uncaughtException 方法 否则通过线程的 getDefaultUncaughtExceptionHandler 方法，获取线程的 defaultUncaughtExceptionHandler 如果显示设置 defaultUncaughtExceptionHandler，调用其 uncaughtException 方法来处理异常 否则判断异常是否是 ThreadDeath 是的话不做任何处理 否则通过标准错误输出打印异常信息 注意，通常我们需要在执行的 run 方法中主动捕获异常，因为线程默认的异常处理会将异常信息出处到标准错误，在生产环境中往往会被丢弃，导致我们无法定位异常原因。 创建多少线程合适？最后，我们来看一个问题。我们使用多线程，是为更有效地利用系统资源，提高程序的响应速度和吞吐量，那么创建多少线程合适呢？是不是越多越好呢？ 显然不是，多线程能够提升CPU 的利用率和 I/O 的利用率，但如果某个资源已经达到了瓶颈，再增加线程不但不会提升性能，还会使性能变得更差，原因是增加了线程切换的成本。所以创建多少线程合适，要看多线程具体的应用场景。 1）对于CPU密集型任务，设置为和 CPU 核心数相当或稍大，就可以充分利用CPU资源； 2）对于IO密集型任务，我们可以将线程池适当开大点，以便众多线程轮流使用CPU，提升CPU利用率，理论上来说可以遵循以下公式来设置线程数： 1pool_size = N * (cpu_time + io_time) / cpu_time 应用上述公式有两个前提，一是没有瓶颈资源，任务执行依赖的资源能够满足所有的线程，二是没有瓶颈操作，任务的执行效率不会随着线程数增加而下降。 瓶颈资源很好理解，这个公式是为了让 CPU 的利用率达到 100%，但如果在这之前 IO 资源已经成了瓶颈，或者线程执行任务依赖的其它资源，比如数据库连接池，达到了瓶颈状态，这种情况下增加更多线程并不会提升性能。 瓶颈操作怎么理解呢？我们使用多线程本质上是一种并行优化，但如果线程执行的任务存在必须串行执行的部分，当代码执行到这部分逻辑时，即使在执行 IO 操作时把 CPU 资源让了出来，其他线程因为拿不到锁，也无法使用 CPU 资源。这种情况下增加更多线程也不会增加性能。 4）很多情况下，对于 io_time 和 cpu_time 的比例，以及是否有瓶颈操作和资源，不太容易得出准确的估计，通常我们会根据经验值进行设置，然后做好监控统计，随时调整优化线程数； 5）在一些比较重要的业务场景下，或者说线程数量设置不准确，可能导致非常大的影响时，我们需要通过压测来确定线程数，保证服务稳定性； 6）最后，业务流量、io_time和cpu_time的比例、任务执行的瓶颈操作和瓶颈资源也不是一成不变的，所以做好监控，按需调整是非常有必要的。 参考 Java线程（中）：创建多少线程才是合适的？ Thread","link":"/2024/02/26/thread/"},{"title":"服务上云那些事","text":"背景和挑战我们的服务是一款海外短视频产品，日活 1500 万，印度市场排名第二，是 ** 公司日活最高、数据最好的出圈产品。当时因为业务计划出售，需要最高优先级将后端服务迁移到 AWS 公有云。整个迁移工作面临以下几个挑战： 迁移周期短 迁移和业务增长并行 数据量大、并发高 跨团队、跨部门、跨公司协作由于用户规模大、业务场景复杂、数据量大、请求并发高，要在短时间内完成迁移工作，保证服务迁移和业务增长并行，同时保证服务的稳定性，是一个很大的挑战。 迁移方案原服务架构 上图是原服务架构。承接了 1500 万日活，接入层服务峰值 QPS 136k，首页 Feed 流峰值 QPS 3.8k，使用 10 个MySQL 集群，约 5.7T 数据，5 个 Redis 集群，约 750G 数据，2 个 MongoDB 集群，约 100G 数据，4 个 ES 索引，约 280G 数据，1 个 Hbase 集群，约 180G 数据。 迁移技术评估迁移涉及到的组件技术选型和难度评估如下表所示。 自建云平台 AWS 迁移技术要点 迁移技术难度 云主机 Amazon EC2 平滑迁移 低 负载均衡器 Amazon ELB 平滑迁移 低 MySQL Amazon Aurora 平滑迁移 中 MongoDB Amazon DocumentDBMongoDB on EC2 平滑迁移，修改部分代码平滑迁移，修改部分代码，维护工作大 中低 Redis Amazon ElastiCache for RedisRedis on EC2 平滑迁移，修改部分代码平滑迁移，修改部分代码，维护工作大 低低 RocketMQ Amazon SQS 重新技术选型，修改较多代码 高 Talos AWS Kinesis/Amazon MSK 重新技术选型，修改较多代码 高 EMQ Amazon SQS 重新技术选型，修改较多代码 高 Elasticsearch Amazon OpenSearch 平滑迁移，修改部分代码 中 FDS Amazon S3 重新技术选型，修改较多代码 低 HBase Amazon EMR HBase on S3DynamoDBHbase on EC2 平滑迁移，修改部分代码重新技术选型，修改较多代码平滑迁移，修改部分代码，维护工作大 中高低 短信服务 Amazon Pinpoint 重新技术选型，修改部分代码 低 迁移大原则1）保稳定 业务低峰期迁移（北京时间早上6~8点） 尽可能使用托管服务，尽量少改代码 迁移前必须通过功能测试和性能测试 多批次小数据量迁移，将每次迁移影响降到最小 2）可回滚 原有环境可以回滚，如果不能则需要有数据实时同步和定时数据备份 提前测试回滚，如果不能则测试备份恢复操作可以成功 3）有预案 迁移前预想到可能导致迁移失败的情况 针对可能导致失败的情况，提前准备好脚本和命令 每个组件正式迁移前，提前演练 总体方案首先迁移 MySQL、Redis、MongoDB、ES 等数据库，然后改造其它中间件和基础组件，最后使用同一套代码在 AWS 侧部署新服务，通过流量接入层将读写流量逐渐迁移到新服务。 对比行业最佳实践方案根据行业中最佳实践，通常会采用以下流程所示方案： 如果我们的服务迁移应用这种方案，存在以下问题： - 大量三方调用，模拟数据成本高 线上问题在最后阶段暴露，排期不可控 业务需求与迁移并行，要维护两个分支 提前部署，将会对基础服务的依赖提前 相较而言，上一种方案没有以上的问题，而且更容易保证数据的一致性。 迁移过程数据库迁移基本方案 方案 描述 优点 缺点 双写 通过双写保证数据的一致，平滑迁移 可以保证数据一致性；不停服，用户无感知 开发工作量大，周期长 停服迁移 原数据库停写，数据完全同步后，切换到 AWS 数据库 可以保证数据一致性 停写期间服务可用性受损 直接切换 服务直接切换到 AWS 服务 操作简单 容易导致数据不一致，出现主键冲突等错误，进而导致一些不可预料的问题，风险高 数据库迁移有如上三种方案，其中直接切换无法保证数据的一致性，风险高，通常情况下不会选择。 双写方案预期效果最好，但是开发工作量最大。我们业务使用了 MySQL、MongoDB、Redis、ES、Hbase 等多种数据库，部署项目数量 15+，涉及写数据的逻辑极多，想要实现数据双写，代码改动的工作量非常庞大，代码改动多也意味着潜在风险多、开发周期长。综合考虑开发周期与迁移风险，我们也放弃了这种方案。 最终我们选择停写迁移的方案。停写后，确保增量数据完全同步成功，数据一致性校验通过后，切换为新数据源。同时我们采取了如下措施来减少停写造成的影响： 在业务低峰期进行迁移； 增量数据同步尽可能使用自动化工具，或提前准备好数据迁移和数据校验脚本，缩短停写时间； 提前缩减服务节点，缩短切换数据源部署时间。我们评估了各个数据库组件低峰期停写对业务造成的影响，确定了可以接受的最大停写时间，经过模拟演练，验证了停写方案的可行性。 MySQL 迁移迁移方案通过binlog机制实现原 MySQL 到 Aurora 的数据迁移，RTO：10分钟 RPO：1分钟。具体步骤如下： 正向同步： 1）开启 Aurora binlog 功能，将 Aurora 的写节点设置为原 MySQL 的从节点，通过 binlog 将存量数据同步过来； 2）将只读流量通过 Proxy 切换到 Aurora 集群只读节点； 反向同步： 3）将 MySQL 设置为只读，将 Aurora 写节点设置为主节点，原 MySQL 主节点设置为从节点，实现数据的反向同步，并将写流量通过 Proxy 分发给 Aurora 主节点； 4）将业务代码的写流量指向 Aurora 的主节点 Endpoint，读流量指向 Aurora 的读Endpoint，和 Proxy 剥离； 5）开启Aurora Backtrack功能。 Aurora 选型通过性能测试确定 Aurora 配置。测试均开启Aurora Binlog，使用 sysbench 测试。自建云平台 MySQL 集群资源比（CPU 核数/内存）是 1:4， Aurora 资源比是 1:8，所以下面测试有以内存一致为前提测试，有以核心数一致为前提测试。 自建云平台配置 AWS 配置 结论 内存一致 16C/64G/1T8C 64G/4750Mbps AWS 8C/64G/4750Mbps 与自建云平台侧 16C/64G/1T 配置 性能测试相当，但随着并发的增加，达到 128 并发线程后，Aurora 性能下降比自建云平台侧较多，鉴于线上 Threads_running 正常情况下低于 24，所以自建云平台侧 16C/64G/1T 配置，可以使用 Aurora 8C/64G/4750Mbps 进行代替 内存一致 32C/128G/4T 16C/128G/4750Mbps AWS 16C/128G/4750Mbps 配置性能要比自建云平台侧 va8.5 32C/128G/4T 配置性能低 20%，响应时间在跨机房的情况下和自建云平台侧同机房响应时间基本一致，结合跨机房 35% 的性能损耗，总体还是 AWS 16C/128G/4750Mbps 配置要优 核心数一致 32C/128G/4T 32C/256G/9500Mpbs AWS 32C/256G/9500Mpbs 配置 与 自建云平台侧 va8.5 32C/128G/4T 配置性能相当，随着并发的增加 AWS 侧性能，AWS 性能比较稳定，最大吞吐虽然有下降，但 P99 响应时间 一直比自建云平台侧低 2 倍 MongoDB 迁移通过 MongoShake 和 oplog 实现 MongoDB 的数据迁移，RTO：10 分钟 RPO：10 分钟。具体步骤如下： 1）通过 MongoShake 将 MongoDB 的存量数据同步到目标环境； 2）将源 MongoDB 设置为只读权限； 3）将业务流量切换至目标环境的 MongoDB； 4）关闭数据同步； 5）每10分钟做一次备份。 开源版本的 MongoDB 没有开启 PID 功能，如果要实现反向同步必须保证是空数据库同步，故改为离线备份方式。 Redis 迁移通过 RedisShake 实现 Redis 到 ElastiCache Redis 的数据迁移，通过 ElastiCache 的 Backup 实现小时级的数据反向同步，RTO：10分钟 RPO：10分钟。具体步骤如下： 正向同步 1）通过 RedisShake 将原 Redis 的存量数据同步到目标环境的 ElastiCache Redis 上； 2）将业务流量切换到目标环境的 ElastiCache Redis 上； 3）写脚本实现 ElastiCache Redis 的定期备份，并拷贝到 S3 上（ ElastiCache Redis 默认不开启psync，可以向后台申请开启，但开启后不能保障 SLA，故放弃 psync 反向同步）； 反向拷贝 4）原集群实时同步 ElastiCache Redis 的备份，当 ElastiCache Redis 出现问题时可以及时回滚到原集群。 Redis 迁移特殊的一点是没有采用类似 MySQL、MongoDB 等组件采用的停写迁移方案。主要原因是 Redis 停写操作难度较高，需要业务上进行代码改造来实现，代码改动的工作量非常庞大。 直接切换的方案在迁移过程中可能出现老数据覆盖新数据的问题，但考虑到迁移窗口在业务低峰期，Redis 写 QPS 很低，而且 Redis 中大部分数据属于缓存数据，造成的影响有限。所以我们最终选择了直接迁移的方案。 ES 迁移通过 ElasticSearch 的 Snapshot 功能实现 ElasticSearch 数据迁移。RTO：10 分钟 RPO：20 分钟。具体步骤如下： 1）将原 ElasticSearch 索引的第一次（全量数据）Snapshot 到 S3（注册 S3 为 Snapshot 的仓库），并恢复到目标环境的 OpenSearch 上； 2）将原 ElasticSearch 账号设置为只读，将原 ElasticSearch 索引的第二次（增量数据）的 Snapshot 导出到 S3，并恢复到目标环境的 OpenSearch 上； 3）切换写读写流量到目标环境的 OpenSearch上； 4）写 Cronjob 实现 20 分钟一次的 Snapshot 备份。 注：ElasticSearch 7.7（OpenSearch）版本的 Snapshot 无法在 ElasticSearch7.6.2（原集群版本）上恢复，所以采用离线 Snapshot 的备份方式。 Hbase 迁移通过 HBase 的 Snapshot 功能实现 HBase 数据迁移。RTO：30分钟 RPO：10分钟。具体步骤如下： 1）业务侧停写，将原 HBase 表数据通过 Snapshot 导出到 HDFS 上，再 distcp 到目标环境 S3 上； 2）将 S3 上的 Snapshot 恢复到 EMR HBase 上； 3）将业务流量切换至目标环境的 EMR HBase 上； 4）开启 EMR HBase 集群之间的 replication 功能，基于 WAL 日志实现同步； 5）同时定期对重要表进行 Snapshot 备份。 AWS 的 HBase 是 EMR HBase on HDFS 模式，底层是 i3 的 EC2，而 EMR 默认是单 AZ 部署，所以在已有两个 HBase 集群分别部署到不同的 AZ 上，同时对重要的表做了 replication 的操作。 服务改造底层存储数据库迁移完成后，开始对服务中使用的基础组件进行改造，具体措施如下： 自建云平台侧技术组件 改造方式 RocketMQ 替换为 Amazon SQS，步骤如下：1. 上线 SQS 生产者和消费者，新增数据写入 SQS；2. 原 MQ 消费者继续消费历史数据；3. 历史数据消费完成后，下线原 MQ EMQ 同RocketMQ Talos 替换为 Amazon MSK ，步骤和 RocketMQ、EMQ 类似 FDS 替换为 Amazon S3，通过双写完成数据迁移 Thrift 无需改造 Zookeeper 在 Amazon EC2 上自建 Zookeeper 短信服务 替换为 Amazon Pinpoint，由于 Pinpoint 只是发送通道，需要自己实现验证码生成和验证逻辑 日志系统 通过 MSK 和 OpenSearch 自建日志收集系统 中台评论 自建服务，去中台依赖 中台审核 自建服务，去中台依赖 服务改造完成后，在 AWS 侧部署一套服务，通过 Nginx 逐步切换流量，最终完整个服务迁移。 其它技术问题时区问题原服务机器服务都是东八区，而 AWS 是 UTC 时区。 解决措施： 整理哪些组件和服务依赖时区 EC2 可以设置时区 EMR 可以通过 Bootstrap 更改底层 EC2 的时区，Flink/Spark/Hive都默认调EC2的时区 Aurora 可以更改 MySQL引擎的时区 Redis/MSK/OpenSearch 默认是 UTC 时间，可以在写入数据时通过代码指定时区 binlog 问题数据组需要用到业务组的 binlog，并写入到数仓中，原来的解决方案依赖自建云平台的中间件和数仓产品，迁移后不可用。 解决方案： 在 MSK 托管的 connector 上引用 Debezium 将 binlog 日志导入到 MSK 里的 Topic 里 下游 EMR Flink 消费，通过 Flink Kudu 的 connector 写入到数仓中 CI/CD 问题迁移前使用自建云平台的 CI/CD 平台，迁移后需要有另一套 CI/CD 平台方案，并与 Autoscaling Group 结合。 解决方案：使用Jenkins，AWS CodeDeploy，Autoscaling Group实现 具体步骤： 使用 Jenkins 实现 Gitlab 对接 基于 Jenkins worker 节点实现代码编译，不使用 CodeBuild 的原因是原服务有使用修改内核后的 CentOS 编译 C++ 代码的场景，而 CodeBuild 默认没有 CentOS，为了避免使用两套技术栈所以采用了自建 Jenkins worker 节点的方式编译代码 基于 HTTP Plugin 实现和 S3 的交互，将编译好的包上传到 S3 使用 Jenkins 的 Plugin 调 CodeDeploy 部署代码到相应的 Autoscaling Group EC2 上，当 S3 代码出现变化，自动触发 CD 流程 总结和收获托管服务的优势 迁移前 迁移后 安全合规 需要内部法务和安全专家确定，时间周期长 无需考虑，托管服务有各种合规标准 运维工作 需要跨部门支持，耗费大量人工和时间 3 个 SRE 维护整个架构，如有 case AWS 会及时响应 系统可用性 自建云平台无准确评估 托管服务都有 SLA 和最佳实践 性能 基于开源自建 托管服务性能和开源一致，Aurora 性能高于开源 创新 需求需要层层传递，耗费大量人工和沟通时间，且需求较难实现 利用 AWS 托管服务可以随时验证想法，如可以利用托管 AI 服务 Transcribe 进行很多测试 成本 IDC 用法，需要预置资源，浪费较多 大部分托管服务都有弹性，可以随时调整 迁移的心得历经4月，最终顺利完成了整个迁移工作，我们总结了迁移的几个关键点。首先是技术能力方面： 梳理当前架构/设计合理的架构：服务迁移的前提是完全了解服务架构和实现细节； 迁移方案确认：根据实际情况制定合理方案，是服务迁移的关键； 功能测试/性能测试：迁移过程中每个环节都要经过严格的测试和演练，是迁移的基础； 最佳实践：充分了解各组件的最佳实践并合理应用，才能提升效率并保证迁移后服务的稳定性。 然后是项目管理方面： 切分可以并行的业务模块，提升迁移效率； 把控迁移节奏，及时发现风险点； 集中时间和资源解决 Block issue。","link":"/2024/02/27/service-migration/"},{"title":"分库分表——原理篇","text":"为什么要分库分表？垂直方向垂直方向主要针对的是业务。 单库在系统初期，业务功能相对来说比较简单，系统模块较少。 为了快速满足迭代需求，减少一些不必要的依赖。更重要的是减少系统的复杂度，保证开发速度，我们通常会使用单库来保存数据。 系统初期的数据库架构如下： 此时，使用的数据库方案是：一个数据库包含多张业务表。用户读数据请求和写数据请求，都是操作的同一个数据库。 分表系统上线之后，随着业务的发展，不断的添加新功能。导致单表中的字段越来越多，开始变得有点不太好维护了。 一个用户表就包含了几十甚至上百个字段，管理起来有点混乱。 这时候该怎么办呢？答：分表。例如将用户表拆分为：用户基础信息表和用户扩展信息表。 用户基本信息表中存的是用户最主要的信息，比如：账号、登陆类型、昵称、头像、性别、生日、电话、邮件等核心数据。这些信息跟用户息息相关，查询的频次非常高。 而用户扩展表中存的是用户的扩展信息，比如头像识别结果等非核心数据。这些信息只有在特定的业务场景才需要查询，而绝大数业务场景是不需要的。 所以通过分表把核心数据和非核心数据分开，让表的结构更清晰，职责更单一，更便于维护。 除了按实际业务分表之外，上述方案也体现了另一个常用的分表原则：把调用频次高的放在一张表，调用频次低的放在另一张表。 分库系统已经上线已经经历了 N 个迭代的需求开发，功能已经非常完善。系统功能完善，意味着系统各种关联关系，错综复杂。此时，如果不赶快梳理业务逻辑，后面会带来很多隐藏问题，坑越来越多。 这就需要按业务功能，划分不同领域了。把相同领域的表放到同一个数据库，不同领域的表，放在另外的数据库。 例如，将用户、视频、点赞、push 相关的表，从原来一个数据库中，拆分成单独的用户库、视频库、点赞库和 push 库，一共四个数据库。这样按领域拆分之后，每个领域只用关注自己相关的表，职责更单一了，变得更好维护了。 分库分表有时候按业务，只分库或者只分表是不够的。那就需要结合使用分库分表。 水平方向水分方向主要针对的是数据。 单库在系统初期，由于用户非常少，所以系统并发量很小。并且存在表中的数据量也非常少。这时的数据库架构如下： 此时，使用的数据库方案同样是：一个数据库包含多张业务表。 用户读数据请求和写数据请求，都是操作的同一个数据库，该方案比较适合于并发量很低的业务场景。 主从分离系统上线一段时间后，用户数量增加了。此时，单个节点可能扛不住所有的读写请求了。因为大部分场景下都是读多写少，所以我们可以把读库和写库分开。于是，就出现了主从读写分离架构。 这种架构可以解决上面提到的单节点无法承载所有请求压力的问题，而且随着读请求量增加，还可以增加从库的数量，通过负载均衡来保障读请求的性能不会下降。除此以外相对于单库的方案，还有以下优势： 主从负责各自的写和读，极大程度的缓解 X 锁和 S 锁争用 能够更好的保证系统的稳定性。因为如果主库挂了，可以升级从库为主库，将所有读写请求都指向新主库，系统又能正常运行了 在用户量还没那么大的时候，可以选择一主一从的架构，所有的写数据请求，都指向主库。一旦主库写完数据之后，立马异步同步给从库。这样所有的读数据请求，就能及时从从库中获取到数据了（会存在一定延迟）。 但这里有个问题就是：如果主库挂了，升级从库为主库，需要将所有读写请求都指向新主。但此时，可能这个新主根本扛不住所有的读写请求，而且读写分离的架构直接不存在了，读写请求之间可能出现锁竞争、数据库连接竞争等问题，所以我们一般会使用一主多从的架构。 以上图一主多从的架构为例，如果主库挂了，可以选择从库 1 或从库 2 中的一个，升级为新主库。 假如我们在这里升级从库 1 为新主，则原来的从库 2 就变成了新主库的从库了。如果查询请求量再增大，我们还可以将架构升级为一主三从、一主四从…一主 N 从等。 分库上面的读写分离方案确实可以解决读请求导致的主节点扛不住（连接资源不足或 CPU 成为瓶颈）的问题。 但如果某个库，比如：点赞库。如果点赞的请求量非常大，即写请求本身的请求量就很大，一个主库库根本无法承受住这么大的压力。这个时候该怎么办？答：分库。 例如，这里将点赞库库拆分成了两个库，每个库的表结构是一模一样的，只有存储的数据不一样。 分表用户请求量上来了，带来的势必是数据量的成本上升。即使做了分库，但有可能单个库中的某个表数据量过大，比如：视频表累计超过 1.5 亿的数据。 根据经验值，单表的数据量应该尽量控制在 2000 万以内，性能是最佳的。如果有几千万级甚至上亿的数据量，用单表来存，性能会变得很差。这里 2000 万只是经验值，实际值和数据库产品类型、版本、机器配置、存储大小等也有关系，需要根据实际情况分析。 数据量过大之所以会导致性能下降，是因为 MySQL 在 InnoDB 存储引擎下创建的索引都是基于 B+ 树实现的，所以查询时的 I/O 次数很大程度取决于树的高度，随着 B+ 树的树高增高，I/O 次数增加，查询性能也就越差。 这时该怎么办呢？答：分表。 例如，这里将视频库中的视频表，拆分成了 32 张表，每张表的表结构是一模一样的，只是存储的数据不一样。如果以后视频数据量越来越大，只需再多分几张视频表即可。 分库分表当系统发展到一定的阶段，用户并发量大，而且需要存储的数据量也很多。这时该怎么办呢？答：需要做分库分表。 例如，这里将点赞库拆分成了两个库，每个库都包含了 128 张点赞表。如果有用户请求过来的时候，需要根据分表规则将其路由到其中某个库的某张表。 总结上面主要从垂直和水平两个方向介绍了我们的系统为什么要分库分表。垂直方向（即业务方向）很简单。在水平方向（即数据方向）上，分库和分表的作用，其实是有区别的，不能混为一谈。 分库：是为了解决主库连接资源不足问题和磁盘 IO 利用率过高问题。 分表：是为了解决单表数据量太大，sql 语句查询数据时，即使走了索引也非常耗时问题。 分库分表：解决上面两类问题。 如果在有些业务场景中，写请求并发量很大，但是数据总量很少，这时可以只分库，不分表。 如果在有些业务场景中，写请求并发量不大，但是数据总量很多，这时可以只分表，不分库。 如果在有些业务场景中，写请求并发量大，并且数据总量也很多时，需要分库分表。 分库分表的方案有哪些？在看具体的方案前，我们首先需要认识到，分库分表实施方案需要关注的两个问题。 1）路由算法 —— 关注数据偏斜问题 一个良好的分库分表方案，它的数据应该是需要比较均匀的分散在各个库表中的，否则有的库/表的数据很多，有的库/表数据很少，会导致以下问题： 业务上的表现经常是延迟忽高忽低，飘忽不定 后续的扩容步调不一致，无法统一操作 2）扩容方案 —— 关注方案可持续性问题 业务数据量级和业务流量未来进一步升高达到新的量级的时候，我们的分库分表方案可以持续使用，也就是能够实现平滑扩容。 理解了这两个问题，接来看下具体的分库分表方案。 Range 分库分表该方案根据数据范围划分数据的存放位置。 举个最简单例子，我们可以把订单表按照年份为单位，每年的数据存放在单独的库(或者表)中。 1234public static String rangeShardByYear(String orderId) { int year = Integer.parseInt(orderId.substring(0, 4)); return &quot;t_order_&quot; + year; } 这种方案简单直观，但特定业务场景下才能使用。而且存在以下缺点： 可能存在热点数据问题 新库/新表的追加需要提前处理 交叉范围内的数据需要特殊处理，比如某个定时任务需要处理昨天的数据，元旦那一天的逻辑需要特殊处理。 Hash 分库分表该方案是对选择的分片 key（表中的某个字段）取哈希，然后根据一定规则映射到具体的数据库和表中。 标准的二次分片法12345678910111213public static ShardCfg shard(String userId) { // ① 算Hash int hash = userId.hashCode(); // ② 总分片数 int sumSlot = DB_CNT * TBL_CNT; // ③ 分片序号 int slot = Math.abs(hash % sumSlot); // ④ 计算库序号和表序号 int dbIdx = slot / TBL_CNT ; int tblIdx = slot % TBL_CNT ; return new ShardCfg(dbIdx, tblIdx); } 1）数据偏斜问题：只要 Hash 值足够均匀，那么理论上分片序号也会足够平均，于是每个库和表中的数据量也能保持较均衡的状态。 2）平滑扩容问题：翻倍扩容后，我们的表序号一定维持不变，库序号可能还是在原来库，也可能平移到了新库中(原库序号加上原分库数)，这样只需要基于库迁移数据，而且只需要移动一半的数据，满足扩容可持续要求。 以 10 库 100 表为例，分片序号为 986 的数据存储在第 9 库第 86 表。 翻倍扩容后（10 库-&gt;20 库），分片序号可能还是 986，也可能变成了 1986，所以表序号一定维持不变，还是 86，库序号可能是 9，也可能是 19。 方案缺点： 翻倍扩容法前期操作性高，但是后续如果分库数已经是大几十的时候，每次扩容都非常耗费资源。 不过要注意，在设计分片规则的时候，不要犯下面这两个错误。 错误方案一： 12345678public static ShardCfg shard(String userId) { int hash = userId.hashCode(); // 对库数量取余结果为库序号 int dbIdx = Math.abs(hash % DB_CNT); // 对表数量取余结果为表序号 int tblIdx = Math.abs(hash % TBL_CNT); return new ShardCfg(dbIdx, tblIdx); } 用 Hash 值分别对分库数和分表数取余，得到库序号和表序号。这种方式为什么是错误的？ 以 10 库 100 表为例，如果一个 Hash 值对 100 取余为 0，那么它对 10 取余也必然为 0。这就意味着只有 0 库里面的 0 表才可能有数据，而其他库中的 0 表永远为空。 类似的我们还能推导到，0 库里面的共 100 张表，只有 10 张表中(个位数为 0 的表序号)才可能有数据。 这就带来了非常严重的数据偏斜问题，因为某些表中永远不可能有数据。 错误方案二： 12345678910111213public static ShardCfg shard(String userId) { // ① 算Hash int hash = userId.hashCode(); // ② 总分片数 int sumSlot = DB_CNT * TBL_CNT; // ③ 分片序号 int slot = Math.abs(hash % sumSlot); // ④ 计算库序号和表序号的错误案例 int dbIdx = slot % DB_CNT ; int tblIdx = slot / DB_CNT ; return new ShardCfg(dbIdx, tblIdx); } 只要 Hash 值足够均匀，那么理论上分片序号也会足够平均，于是每个库和表中的数据量也能保持较均衡的状态。所以这种方案没有数据偏斜的问题，那它为什么是错误的？ 在计算表序号的时候，依赖了总库的数量，那么后续翻倍扩容法进行扩容时，会出现扩容前后数据不在同一个表中的现象。 如上图中，例如扩容前 Hash 为 1986 的数据应该存放在 6 库 98 表，但是翻倍扩容成 20 库 100 表后，它分配到了 6 库 99 表，表序号发生了偏移。 这样的话，我们在后续在扩容的时候，不仅要基于库迁移数据，还要基于表迁移数据，非常麻烦且易错。 一致性哈希法关于一致性 Hash 的具体原理这里不做介绍。 实际使用这种方案时，我们通常会将每个实际节点的配置持久化在一个配置中心或者是数据库中，配置一般包括一个[StartKey，Endkey)的左闭右开区间和一个数据库节点信息，例如： 应用启动时或者是进行切换操作的时候会去加载配置。 123456789101112131415private TreeMap&lt;Long, Integer&gt; nodeTreeMap = new TreeMap&lt;&gt;(); @Override public void afterPropertiesSet() { // 启动时加载分区配置 List&lt;HashCfg&gt; cfgList = fetchCfgFromDb(); for (HashCfg cfg : cfgList) { nodeTreeMap.put(cfg.endKey, cfg.nodeIdx); } } public ShardCfg shard(String userId) { int hash = userId.hashCode(); int dbIdx = nodeTreeMap.tailMap((long) hash, false).firstEntry().getValue(); int tblIdx = Math.abs(hash % 100); return new ShardCfg(dbIdx, tblIdx); } 一致性 Hash 是针对分片键的 Hash 值进行范围配置。正规的一致性 Hash 算法会引入虚拟节点，每个虚拟节点会指向一个真实的物理节点。引入虚拟节点有如下作用： 节点数量多了后，节点在哈希环上的分布就相对均匀了，可以提高节点的均衡度； 当节点变化时，会有不同的节点共同分担系统的变化，不仅可以保证节点的均衡度，而且会提高系统的稳定性。比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。 但是用在分库分表上，一般大部分都只用实际节点，引入虚拟节点的案例不多。主要有以下原因： 如果虚拟节点较多，节点配置信息在内存中的占用也会比较多。 从多个节点迁移数据，不如从单个节点迁移数据（通过主从复制后再删除冗余数据）简单可控。 分库分表中通常是新增节点，不存在某个节点被移除导致下个节点压力突增的问题 分库分表后如何平滑扩容？翻倍扩容法翻倍扩容法的主要思路是每次扩容，库的数量均翻倍处理，而新增的数据库中通常是由原数据库通过主从复制方式将原表数据复制一份过来，然后再升级成主库提供服务，所以也称为”从库升级法”。 理论上，经过翻倍扩容法后，我们会多一倍的数据库用来存储数据和应对流量，原先数据库的磁盘使用量也将得到一半空间的释放。 流程具体的流程大致如下： 时间点 t1：为每个节点都新增从库，开启主从同步进行数据同步。 时间点 t2：主从同步完成后，对主库进行禁写。 此处禁写主要是为了保证数据的正确性。若不进行禁写操作，在以下两个时间窗口期内将出现数据不一致的问题： 断开主从后，若主库不禁写，主库若还有数据写入，这部分数据将无法同步到从库中 因为应用服务识别到分库数翻倍的时间点无法严格一致，在某个时间点可能两台应用使用不同的分库数，运算到不同的库序号，导致错误写入 时间点 t3：同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。 时间点t4：从库升级为集群节点，业务应用识别到新的分库数后，将应用新的路由算法。 时间点 t5：确定所有的应用均接收到库总数的配置后，放开原主库的禁写操作，此时应用完全恢复服务。 最后启动离线的定时任务，清除各库中的约一半冗余数据。 总结通过上述迁移方案可以看出，从时间点 t2 到 t5 时间窗口呢内，需要对数据库禁写，相当于是该时间范围内服务是部分有损的，该阶段整体耗时通常是在分钟级范围内。若业务可以接受，可以在业务低峰期进行该操作。 如果应用无法容忍分钟级写入不可用，例如写操作远远大于读操作的应用，此时可以： 通过中间件缩短停写的时间，比如借助 Proxy 层可以实现秒级的停写 双写 该方案主要借助于 MySQL 强大完善的主从同步机制，能在事前提前准备好新的节点中大部分需要的数据，节省大量的人为数据迁移操作。但是缺点也很明显，一是过程中整个服务需要停写，业务是有损的，二是每次扩容均需要对库数量进行翻倍，会提前浪费不少的数据库资源。 一致性哈希扩容假如当前数据库节点 DB0 负载或磁盘使用过大需要扩容，我们通过扩容可以达到例如下图的效果。 下图中，扩容前配置了三个 Hash 分段，发现[-Inf，-10000)范围内的的数据量过大或者压力过高时，需要对其进行扩容。 流程主要步骤如下： 时间点 t1：针对需要扩容的数据库节点增加从节点，开启主从同步进行数据同步。 时间点 t2：完成主从同步后，对原主库进行禁写。此处原因和翻倍扩容法类似，需要保证新的从库和原来主库中数据的一致性。 时间点 t3：同步完全完成后，断开主从关系，理论上此时从库和主库有着完全一样的数据集。 时间点 t4：修改一致性 Hash 范围的配置，并使应用服务重新读取并生效。 时间点 t5：确定所有的应用均接受到新的一致性 Hash 范围配置后，放开原主库的禁写操作，此时应用完全恢复服务。 启动离线的定时任务，清除冗余数据。 总结该方案和翻倍扩容法的方案比较类似，但是它更加灵活，可以根据当前集群每个节点的压力情况选择性扩容，而无需整个集群同时翻倍进行扩容。 分库分表带来的问题有哪些？全局 ID 问题分库分表后，多张单表中的自增主键就一定会发生冲突，不具备全局唯一性。 解决方案： 1）基于某个单表生成自增主键 问题：这个单表就变成整个系统的瓶颈，而且也存在单点问题 优化：基于多个单表+步长做自增主键 2）业务上不依赖数据库的自增 ID 作唯一标识，通过其它方式生成全局 ID 雪花算法 UUID Redis 全表扫描问题单表的时候全表扫描比较容易，但是做了分库分表之后，如果要扫表的话就要把所有的物理表都要扫一遍，实现起来更复杂。 非分片 key 的查询问题 映射法：通过映射表转换 冗余法：基于多个 key 分表 基因法：非分片 key 能转换为分片 key 或者根据非分片 key 同样能获取分表信息 事务问题分库后，不支持事务，想要维护数据的一致性实现起来更复杂。 解决方案： 分布式事务 保证最终一致性：MQ/事后补偿 分页、排序、函数问题分库分表后，不能跨表/库进行分页、排序、函数等操作。 解决方案： 先在不同的分片中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户 使用 NoSQL 实现复杂查询（如 ES） 总结分库分表是一种常用的由于数据量级上涨导致的性能问题的解决方案，但这种方案也不是毫无代价的，应用这种方案的同时也会引入一些新的问题，这些问题的解决成本也都不低，所以要做好评估，当分库分表的收益大于付出的代价才考虑选择这种方案。在《分库分表——实战篇》这篇文章中我介绍了两个实际项目中分库分表的案例，可以作为参考。 另外，我个人认为分库分表的必要性可能会越来越低。因为分库分表本质上是在业务层来解决数据库产品的性能问题，而目前业界已经出现了类似 TiDB 等分布式数据库产品，天然支持水平扩展。另外一些商业数据库，比如 AWS Aurora，性能非常优秀，单表支持上亿数据性能也不会有明显下降。我相信，开源数据库产品达到类似的水平也是时间问题。 所以,有一天分库分表可能会成为一种落伍的技术，但是这种解决问题的思想还是可以借鉴的，比如数据切割的流程可以用于服务迁移、数据库重新选型替换等场景；通过分而治之，降低数据规模，来获取性能优化也是一种很常用的思想。 参考 阿里二面：为什么要分库分表？ 分库分表，我再讲最后一次！ 再有人问你什么是分库分表，直接把这篇文章发给他 MySQL：互联网公司常用分库分表方案汇总！ 分库分表需要考虑的问题及方案 分库分表会带来哪些问题","link":"/2024/02/26/db-sharding-theory/"},{"title":"分库分表——实战篇","text":"基本流程根据分库分表基本原理和方案，这里将通用的操作流程总结为以下几步： 根据要解决的问题，确定基本方案（分库 or 分表？水平 or 垂直？） 根据数据量（当前数据量和增长量）评估分库或分表个数 选分片 key（注意切分数据要均匀） 确定分表规则（hash或range等） 执行（双写/从库升级） 必要时进行扩容（尽量减少数据的移动） 结合这个操作流程，接下来我们看下具体的案例。 点赞表分库分表背景短视频业务中，通过点赞表保存了用户对视频的点赞行为，点赞表结构如下： 12345678910CREATE TABLE user_like ( id bigint(11) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键', user_id varchar(32) NOT NULL DEFAULT '' COMMENT '用户标识', video_id varchar(100) NOT NULL DEFAULT '' COMMENT '视频ID', like_status tinyint(1) NOT NULL DEFAULT '-100' COMMENT '点赞状态', status tinyint(1) NOT NULL DEFAULT '1' COMMENT '删除标志位', create_time timestamp NOT NULL DEFAULT '2018-05-29 00:00:00' COMMENT '创建时间', update_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (id)) ENGINE=InnoDB AUTO_INCREMENT=14246 DEFAULT CHARSET=utf8 COMMENT='用户视频点赞关联表'; 由于产品的日活逐渐上涨，点赞表的数据总量、增量都也随之上涨，当时已经有上亿的数据，单表查询速度已经明显下降，另外因为写数据量较大，数据库主库的 IO 也即将达到瓶颈。所以需要对点赞表进行分库分表。 操作流程 确定基本方案 点赞表面临的问题： 单表数据量太大，查询耗时 写请求量大，磁盘 IO 成为瓶颈 所以确定基本方案为：水平分库+分表 评估分库或分表个数 结合当前数据量级和增量，希望未来两年不再需要扩容，计算后，决定分为 2 个库，每个库分为 128 个表。 这里分为两个库，是指点将点赞数据分为两个库，由于点赞表原先是和其他业务数据放在用一个数据库中，所以这里其实是要进行一个垂直方向上的分库，然后将拆出来的点赞库再水平分为两个库。 每个库之所以分为 128 个表，则是希望再次扩容时，数据库 IO 和 单表数据量能同时达到瓶颈，具体数字的确定需要结合机器配置、数据量、请求量等数据来做估计。 选分片 key 这个根据当前 SQL 逻辑确定即可，点赞表中只有根据用户 ID 查询数据的需求，自然选择用户 ID 作为分片 key 分表规则 标准二次分片法，具体内容在《分库分表——原理篇》中有介绍。 执行这个例子因为即要进行分表，同时还要进行分库，所以在实际操作的时候，我们是分两步来进行的，先分表，然后分库，分库的同时将数据从原库中，迁移到新建的两个库中。 1）分表 分表具体的操作如下所示： 在原库中新建 128 张表 业务代码上线双写逻辑，增量数据同时写入原表和新表 写入新表时要应用分表规则 写原表和写新表要放在一个事务中，保证数据一致性 通过跑任务的方式将原表历史数据同步到新表 同步完成后通过定时任务对全量数据进行校验 间隔一定时间重复执行校验逻辑，验证双写数据的一致性 代码度读据逻辑改为从新表读数据 在改为读新表之前，必要时可以采取双读的方式进行校验，也就是线上业务流量读原表数据的同时，异步读取新表数据进行数据对比，无论是否一致都返回原表数据，因为点赞表逻辑比较简单，我们没有进行这一步 删除双写逻辑，只写新表 经过上述操作，点赞表已经被分为了 128 张表，但是整个数据还是在原库中，下一步就要进行数据库垂直拆分，以及再水平拆为两个点赞库。 2）分库 分库采用主从复制加从库升级的方式，并通过数据代理层来减少主库停写时间，具体操作如下： 新建两个数据库，每个数据库中都有 128 张表 将两个新库的主节点配置原库的从库，通过主从复制的方式，保证三个库中点赞表数据完全一致 业务代码中接入双数据源，应用分库规则，读写新建的两个数据源 注意此时，虽然代码中已经应用了分库规则，并且数据库配置也改为了新建的两个库的地址，但是我们中间接入的是代理层，两个代理依然指向了原数据库 然后再代理层进行切换，直接指向新库，服务开始开始读写新库,借助代理层的能力，1 秒内可以完成切换，几乎不停写，服务基本无损。 最后，跑任务删除两个新库中各自的冗余数据（主从同步时同步的是全量数据） 小结上述案例，数据表和业务场景并不复杂，通过分库分表可以解决性能问题和资源瓶颈，同时并没有引入其它问题，所以是一个比较典型的适合分库分表的场景。 视频表分表背景视频表字段过多，单表业务逻辑过于复杂，各种各样的 SQL 非常难以维护和服用，另外单表数据量超过 1.5 亿，查询性能也有下降。 面临这样的问题时，很容易想到分表，但是因为这个表的业务比价复杂，分库分表的代价也比较高，我们当时先调研了其他方案。 比如从新进行技术选型，通过 MongoDB 来重构业务，还是因为复杂性，工作量太大，风险太高，可行性不大；另外也调研了声称兼容 SQL 的分布式数据库，但还是无法 100% 兼容，也不可行。最终还是决定采用分表的方案。 操作流程 确定基本方案 视频表面临的问题： 单表数据量太大，有查询性能下降的风险 但表字段太多，不好维护所以确定基本方案为：垂直分表+水平分表 评估分库或分表个数 如何确定具体数字和上一个案例的思路是一样的，这里直接给结论： 水平分表：32 个表 垂直分表：4 类信息（4个表） 选分片 key 视频 ID 和 用户 ID 都有查询需求，所以需要按照两个维度进行分表，不过再按用户 ID 分表时，仅保留了必要字段 分表规则 标准二次分片法 第五步：执行 面临的问题前面也提到了，因为这个表的业务比较复杂，所以分表遇到了一些问题，这里逐一介绍下。 1）全表扫描问题 原先存在一个定时任务，会定期扫描全表数据，和其它数据源如 MonogDB、ES、推荐内容池中的视频数据进行对比，及时发现不一致的情况，分表后想要进行全表扫描，这块逻辑实现变得更加复杂。 2）非分片 key 的查询问题 前面已经提到了，有根据不止一个 key 的查询需求，所以才去了冗余分表方案，同时采用的一个优化是没有冗余所有字段，仅保留了部分必要字段。 3）复杂查询问题 原先一些复杂查询用到的字段被拆分到了不同表中，无法执行了。这类查询不多，而且不是核心业务场景，所以我们不希望为了支持这类需求，依然容忍表中过多的字段。最终采用的方案是修改业务调用方，改为从 ES 中查询数据 4）查询排序问题 原先一些查询用到的排序字段被拆分到了不同表中，基于和上述第三点相同的理由，我们没有在表中保留冗余字段，而是分别查询后，在内存中进行排序。 5）DML 明显增多 迁移过程中，双写逻辑上线后，DML增长了 9 倍，不符合预期。后定位到原因是在批量更新数据的任务中，由于分表，变成了多次批量。采取的解决是首先按分表规则聚合数据，再批量更新数据。 6）服务负载升高 读取新表后，服务负载明显升高，需要加机器保证服务稳定性。定位到原因是分表导致单次查询变为并行的多表查询导致的，采取了的解决方案是对调用方逻辑优化，只查询必要的字段，减少查询任务量 原先因为是单表，为了复用查询方法，无论业务方需要什么字段，都会查询全量字段。分表过程中，为了保证底层修改对调用方透明，依然会返回所有字段，所以需要并行查询多表，但实际上大部分调用方不需要用到所有字段 小结视频表作为短视频业务的基础数据表，涉及的业务多且复杂，不仅导致工作量大，而且在执行方案前后都遇到了不少问题。另外，分表后，整体的灵活性和可维护性其实都受到了一定影响。 对于类似的业务场景，相比于在不得已的时候做分库分表，其实更好的方案是做好前期的技术规划。在业务迭代的过程中，能更早的发现未来可能存在的瓶颈，提前做出应对，这样也许可选的方案会更多一些。 总结本文介绍的两个分库分表的案例，基本遵循了标准的分库分表方案和操作步骤。具体原理和细节和可以参考《分库分表——原理篇》这篇文章。如果有类似场景的话，可以作为参考。但更重要的是，我们要看到分库分表的收益和代价，在做技术方案时做好权衡。","link":"/2024/02/28/db-sharding-practice/"},{"title":"如何进行数据库性能优化？","text":"慢 SQL 原因及方案SQL 执行慢的原因有很多，比如下面这些： 索引问题 索引失效 索引设计问题 MySQL 选错了索引 复杂查询 数据量过大 锁竞争 硬件资源不足 数据库负载过高 数据库配置问题 针对不同的原因，需要采用不同的方案： 索引问题像索引失效和索引设计问题，是 SQL 设计之初就可以发现和避免的，一方面对索引原理要有基本的掌握，另一方面在 SQL 上线前可以通过 expalin 查看执行计划进行规避。 MySQL 选错索引可能是由于不同的原因导致的，比如数据库统计信息不准确，可以通过 analyze table t 命令来重新统计索引信息。 另外更常见的原因是，MySQL 查询优化器分析得出的理论上的最佳索引，因为实际数据分布的原因，查询速度并不是最快的。这里描述比较抽象，文章后面 第一个 SQL 优化案例就是一个 MySQL 选错索引的例子，可以结合起来理解。 这种情况下就需要我们采取一定的措施去对索引进行修正。常用的方案有以下几种： 通过 force index 强制指定索引 修改 SQL 语句，引导 MySQL 使用我们期望的索引 新建一个更合适的索引来给优化器选择，或者删掉误用的索引 其中，很多人不太推荐使用 force index ，一是将数据库的问题放在了业务中来解决，设计上不够优美，二是把索引名耦合进了 SQL 语句中，索引名改了后，SQL 也得修改，三是迁移到别的数据库的话，这个语法未必兼容，四是修改 SQL 语句加上 force index 之后还要测试和发布，整个过程不够敏捷。 第二种通过修改引导数据库的方式可能导致 SQL 的可读性变得很差，让人不理解设计者的意图，往往不被推荐使用。 第三种，增加和删除索引是比较好的方案，但应用场景非常有限，其它时候就只能使用前面两种方案了。 复杂查询复杂查询是指 SQL 查询语句本身过于复杂，可能包含多个连接、嵌套子查询、聚合函数等，导致数据库需要花费更多的时间来解析和执行查询。 这种场景下如果对数据库查询效率还有比较高的要求，则可以考虑其它对复杂查询支持更加好的数据库，比如 ES。 如果不要求数据库查询效率，比如离线统计需求、运营后台查询需求，为了避免慢查询 SQL 占用大量连接影响线上业务，可以划分出单独的从库实例提供给这类 SQL 使用。 数据量过大单表数据量过大，则需要考虑分表：《分库分表——原理篇》 锁竞争锁竞争可能是存在需要频繁更新的热点数据，也可能是存在长事务导致的。热点数据的话可以考虑通过将一行改成逻辑上的多行来减少锁冲突，或者通过写缓存，异步更新数据库的方式避免锁冲突。 如果是长事务，则需要进一步分析导致长事务的原因，采取相应的解决措施，比如在开发过程中，尽可能的减小事务范围，少用长事务。另外，如果事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 硬件资源不足数据库服务器的硬件资源不足，例如 CPU、内存、磁盘等，无法满足大量查询请求或者写请求的处理需求，导致负载增加。这种情况下可以采取的方案，包括升级数据库硬件配置，或者增加从节点承接更多的读流量，或者通过分库分担写流量。 数据库负载过高上面也提到了，数据库负载过高可能是由于硬件资源不足导致的。但有时可能是一些特殊场景，比如双十一、促销活动等导致的请求突增，这时候如果采取升级配置、增加节点等方案成本上可能不是那么划算，则可以考虑增加缓存来缓解数据库压力。 数据库服务器配置问题数据库服务器配置，比如缓冲池大小等，这些配置往往是由 DBA 来掌控的，业务研发不需要也无权进行调整。而且这类配置在经历大量生产环境的考验后通常已经形成了最佳实践，出问题的概率很小。所以生产实践中很少遇到需要调优服务器的参数的情况，但我们分析问题时还是需要考虑到这种可能性。 上面这几种慢 SQL 原因和方案有一个前提，那就是数据库服务器执行 SQl 慢，而另一种也比较常见的情况是，服务器执行 SQL 正常，而客户端出现慢 SQL，这种情况则需要考虑客户端配置，如连接池大小，以及网络延迟等因素的影响。 小结面对不同的问题和原因，我们可以采取不同的措施。另外，从提前规避的角度来思考，不同的开发阶段，需要考虑的问题也不一样。往往越早需要思考，越早能够应用的方案，也是优先级更高的方案。举个例子，针对具体的业务场景选择合适数据库，比选定一个不合适的数据后，再去进行各种优化措施，显然要更好。 这里把所有可以采取的措施，按照开发周期中从早到晚进行一个总结。 选择合适的 DBMS 表设计优化 逻辑查询优化 物理查询优化 加缓存 库级优化 概括下，前两个方案在于选择，中间两个方案是 SQL 的查询优化，最后两个方案在于引入外援，不管是其他类型的数据库，还是更多的同类型的数据库。 数据库调优步骤上面一小节介绍了常见的慢 SQL 原因和解决方案，但当我们真的面对慢 SQL 时，该如何确定是哪种原因呢？下面这张图很好的说明了一般的思考过程和调优步骤。 整个流程分为观察（S）和行动（A）两类操作，通过观察了解数据库整体的运行状态，通过性能分析工具了解执行慢的 SQL 都有哪些，查看具体的 SQL 执行计划，甚至是 SQL 执行中的每一步的成本代价，最终定位问题所在，找到了问题，再采取相应的行动。 关于这张图的具体细节这里就不进行讲解了，可以查看图片来源文章，也就是本文参考文章 2 进行进一步的学习。这里需要指出的一点是，虽然是流程图，但真正进行数据库调优时，并不一定是自上而下顺序进行的，完全可以并行执行多种观察动作，综合得出最可能的一个原因，然后首先针对这个最可能的原因采取措施，进行验证。 数据库调优案例本小结中介绍一些实际业务中遇到比较典型的 SQL 慢查询，分析其原因，介绍当时采取的方案以及效果。相关案例会持续补充。 案例1：数据库选错索引系统中有这样一张表 1234567891011121314CREATE TABLE puri_video_user ( id bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键', user_id varchar(100) NOT NULL DEFAULT '' COMMENT '用户id', doc_id varchar(100) NOT NULL DEFAULT '' COMMENT '内容池统一ID', audit_status tinyint(4) NOT NULL DEFAULT '0' COMMENT '视频审核状态1 待审核 2审核通过 3审核拒绝 4管理员cms设置仅自己可见', visible_status tinyint(4) NOT NULL DEFAULT '0' COMMENT '可见状态, 1:用户设置所有用户可见 2:用户设置仅自己可见', delete_status tinyint(4) NOT NULL DEFAULT '0' COMMENT '用户删除状态 0未删除 1用户自己删除且内容池没有删除 2用户自己删除且内容池删除成功', create_time timestamp NOT NULL DEFAULT '2018-05-29 00:00:00' COMMENT '创建时间', update_time timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY (id), UNIQUE KEY uk_idx_docid (doc_id), KEY idx_create_time (create_time), KEY idx_uid_status (user_id,audit_status,delete_status,visible_status)) ENGINE=InnoDB AUTO_INCREMENT=193268096 DEFAULT CHARSET=utf8mb4 COMMENT='视频用户信息表' 发生慢查询的 SQL 如下， 1select * from puri_video_user where user_id = '724ce5f73221b9ce' and delete_status = 0 and id &lt; 2147483647 order by id desc limit 12\\G explain 查看执行计划如下： 发现 MySQL 同时使用了 PRIMARY 和 idx_uid_status 这两个索引，最后取了交集。推测 SQL 执行慢的原因可能是这两种： 走主键索引扫描数据过多 走 idx_uid_status 索引排序比较耗时 然后对比了强制走主键索引和强制走 idx_uid_status 索引耗时，发现走主键索引的话和优化器给出的索引方案耗时接近，走 idx_uid_status 索引耗时有明显下降。 所以最终确定了通过 force index 强制走 idx_uid_status 索引的方案。上线后慢查询频率确实明显降低，但并未完全消失，关于依然存在的慢 SQL，在案例二中进一步介绍。 案例2：排序数据过多经过案例一种的优化，SQL 如下所示： 1select * from puri_video_user force index(idx_uid_status) where user_id = '724ce5f73221b9ce' and delete_status = 0 and id &lt; 2147483647 order by id desc limit 12\\G 慢查询频率虽然明显降低，但依然存在，查看了几个例子，发现慢 SQL 有这样一个一个特点，就是 user_id 对应的用户，对应的视频总数非常多。因为这条 SQL 需要对满足条件的数据进行排序，如果需要排序的数据越多，则排序越慢，而且可能会使用临时文件进行外部排序，导致查询性能严重下降。 这里也说明方案一中的方案没有完全奏效，对于视频数少的用户效果不错，但是如果视频数很多，依然会因为排序导致慢查询。 这里考虑为什么需要排序，因为查询条件中包含了 user_id 和 delete_status 这两个字段，但是索引 idx_uid_status 则是 user_id, audit_status, delete_status, visible_status 四个字段，delete_status 位于第三个位置，无法利用耳机索引主键的有序性。 所以如果要避免排序，则需要新建 user_id 和 delete_status 的联合索引。 案例3：分库分表《分库分表——实战篇》 总结本文首先介绍了慢 SQL 可能的原因以及对应的方案，还介绍了数据性能优化可以从那几个维度去思考，在实际中按照什么样的步骤去排查问题，选择合适的方案。最后则是在实际业务中的几个数据库性能优化案例，以后遇到一些比较典型的问题，也会持续补充在这里。 参考 当我们思考数据库调优的时候，都有哪些维度可以选择？ 如何使用性能分析工具定位SQL执行慢的原因？ MySQL为什么有时候会选错索引？","link":"/2024/03/03/db-optimizing/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","link":"/tags/ThreadLocal/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"缓存一致性","slug":"缓存一致性","link":"/tags/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/"},{"name":"缓存雪崩","slug":"缓存雪崩","link":"/tags/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9/"},{"name":"缓存穿透","slug":"缓存穿透","link":"/tags/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"},{"name":"BigKey","slug":"BigKey","link":"/tags/BigKey/"},{"name":"HotKey","slug":"HotKey","link":"/tags/HotKey/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"TCP","slug":"TCP","link":"/tags/TCP/"},{"name":"socket","slug":"socket","link":"/tags/socket/"},{"name":"技术成长","slug":"技术成长","link":"/tags/%E6%8A%80%E6%9C%AF%E6%88%90%E9%95%BF/"},{"name":"类加载","slug":"类加载","link":"/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"},{"name":"jvm","slug":"jvm","link":"/tags/jvm/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"NIO","slug":"NIO","link":"/tags/NIO/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"代码质量","slug":"代码质量","link":"/tags/%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F/"},{"name":"设计原则","slug":"设计原则","link":"/tags/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"重构","slug":"重构","link":"/tags/%E9%87%8D%E6%9E%84/"},{"name":"DDD","slug":"DDD","link":"/tags/DDD/"},{"name":"GC","slug":"GC","link":"/tags/GC/"},{"name":"Thread","slug":"Thread","link":"/tags/Thread/"},{"name":"分库分表","slug":"分库分表","link":"/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"},{"name":"服务迁移","slug":"服务迁移","link":"/tags/%E6%9C%8D%E5%8A%A1%E8%BF%81%E7%A7%BB/"},{"name":"数据库迁移","slug":"数据库迁移","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%81%E7%A7%BB/"},{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"领域驱动设计","slug":"领域驱动设计","link":"/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"项目实战","slug":"项目实战","link":"/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"},{"name":"性能优化","slug":"性能优化","link":"/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"SQL 优化","slug":"SQL-优化","link":"/tags/SQL-%E4%BC%98%E5%8C%96/"},{"name":"SQL优化","slug":"SQL优化","link":"/tags/SQL%E4%BC%98%E5%8C%96/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"并发","slug":"java/并发","link":"/categories/java/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"数据库/Redis","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"并发","slug":"Java/并发","link":"/categories/Java/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"网络协议","slug":"网络协议","link":"/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"攻略","slug":"攻略","link":"/categories/%E6%94%BB%E7%95%A5/"},{"name":"JVM","slug":"Java/JVM","link":"/categories/Java/JVM/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"项目实战","slug":"项目实战","link":"/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"},{"name":"MySQL","slug":"项目实战/MySQL","link":"/categories/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/MySQL/"},{"name":"MySQL","slug":"数据库/MySQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"},{"name":"服务重构","slug":"服务重构","link":"/categories/%E6%9C%8D%E5%8A%A1%E9%87%8D%E6%9E%84/"},{"name":"服务优化","slug":"服务优化","link":"/categories/%E6%9C%8D%E5%8A%A1%E4%BC%98%E5%8C%96/"},{"name":"服务迁移","slug":"服务迁移","link":"/categories/%E6%9C%8D%E5%8A%A1%E8%BF%81%E7%A7%BB/"}],"pages":[]}